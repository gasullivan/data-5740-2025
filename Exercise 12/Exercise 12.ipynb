{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "hepkuwjwrk6pfb6v6dd3",
   "authorId": "2206420187358",
   "authorName": "GREGSULLIVAN",
   "authorEmail": "gregsullivan@ciosoglobal.com",
   "sessionId": "8b4dc867-aa55-47c6-afb6-6d134a30b309",
   "lastEditTime": 1763096895854
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060d5fbe-5300-479b-944d-8888962b4139",
   "metadata": {
    "name": "Exercise12",
    "collapsed": false
   },
   "source": "# Exercise 12: DBSCAN Clustering for P-Card Anomaly Detection\n\n**Objective:** Identify unusual government purchase card (P-Card) spending patterns using DBSCAN clustering to detect potential waste or misuse.\n\n**Dataset:** `pcard_summary.csv` - Monthly spending behavior for government cardholders\n\n**Key Variables:**\n- `avg_transaction_amount`: Average dollar amount per transaction\n- `transactions_per_month`: Number of transactions per month\n- `pct_weekend_transactions`: Percentage of transactions occurring on weekends"
  },
  {
   "cell_type": "code",
   "id": "e16223b6-cabc-460d-ad0f-d34c0d58feb5",
   "metadata": {
    "language": "python",
    "name": "Setup"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import NearestNeighbors\nimport warnings\n\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a7cb9cf-f902-4164-9969-2e7003d191f1",
   "metadata": {
    "language": "python",
    "name": "LoadData"
   },
   "outputs": [],
   "source": "#load dataset\ndf_pcard = pd.read_csv('pcard_summary.csv')\n\nprint(f\"Dataset shape: {df_pcard.shape}\")\nprint(f\"Columns: {df_pcard.columns.tolist()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d845e25-8d14-4caf-9ec5-2582917ccfd0",
   "metadata": {
    "language": "python",
    "name": "PreviewData"
   },
   "outputs": [],
   "source": "df_pcard.head(10)\n\ndf_pcard.info()\n\ndf_pcard.describe()\n\n#check for missing values\ndf_pcard.isnull().sum()\n\n#examine department distribution\ndf_pcard['department'].value_counts()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "adefdd77-7ea7-406e-80a7-b9738d6b03e9",
   "metadata": {
    "language": "python",
    "name": "VisualizeDistributions"
   },
   "outputs": [],
   "source": "#let's haev a look at histograms for the numeric variables\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n#transaction amount\naxes[0].hist(df_pcard['avg_transaction_amount'], bins=30, color='steelblue', edgecolor='black')\naxes[0].axvline(df_pcard['avg_transaction_amount'].mean(), color='red', linestyle='--', label='Mean')\naxes[0].set_xlabel('Average Transaction Amount ($)')\naxes[0].set_ylabel('Frequency')\naxes[0].set_title('Distribution of Average Transaction Amount')\naxes[0].legend()\n\n#transaction counts per month\naxes[1].hist(df_pcard['transactions_per_month'], bins=30, color='coral', edgecolor='black')\naxes[1].axvline(df_pcard['transactions_per_month'].mean(), color='red', linestyle='--', label='Mean')\naxes[1].set_xlabel('Transactions per Month')\naxes[1].set_ylabel('Frequency')\naxes[1].set_title('Distribution of Transactions per Month')\naxes[1].legend()\n\n#interesting to look at weekend purchases for business cards\naxes[2].hist(df_pcard['pct_weekend_transactions'], bins=30, color='mediumseagreen', edgecolor='black')\naxes[2].axvline(df_pcard['pct_weekend_transactions'].mean(), color='red', linestyle='--', label='Mean')\naxes[2].set_xlabel('Percent Weekend Transactions')\naxes[2].set_ylabel('Frequency')\naxes[2].set_title('Distribution of Weekend Transaction Percent')\naxes[2].legend()\n\n#show\nplt.tight_layout()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d306da81-e30e-4350-90b5-669e0c2aa2c4",
   "metadata": {
    "language": "python",
    "name": "PairwiseScatterPlot"
   },
   "outputs": [],
   "source": "#create pairwise scatterplot matrix\nfeature_cols = ['avg_transaction_amount', 'transactions_per_month', 'pct_weekend_transactions']\n\n#build pairs to plot\npairplot = sns.pairplot(\n    df_pcard[feature_cols],\n    diag_kind='hist',\n    plot_kws={'alpha': 0.6, 's': 50},\n    diag_kws={'bins': 30, 'edgecolor': 'black'}\n)\n\n#show\npairplot.fig.suptitle('Pairwise Relationships of P-Card Variables', y=1.01, fontsize=14)\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "568913ae-9da1-4f31-b689-7ee314fb514f",
   "metadata": {
    "language": "python",
    "name": "ThreeDScatterplot"
   },
   "outputs": [],
   "source": "#create 3D visualization\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111, projection='3d')\n\n#build scatter plot\nscatter = ax.scatter(\n    df_pcard['avg_transaction_amount'],\n    df_pcard['transactions_per_month'],\n    df_pcard['pct_weekend_transactions'],\n    c='steelblue',\n    alpha=0.6,\n    s=50,\n    edgecolors='black',\n    linewidth=0.5\n)\n\n#setup plot\nax.set_xlabel('Avg Transaction Amount ($)', labelpad=10)\nax.set_ylabel('Transactions per Month', labelpad=10)\nax.set_zlabel('Pct Weekend Transactions', labelpad=10)\nax.set_title('3D View of P-Card Spending Patterns', fontsize=14, pad=20)\n\n#show plot\n#I like this plot, even though in our viz class\n#  we are discouraged from using 3D visualizations\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "982c5627-2327-4865-90a4-7ee6363bf465",
   "metadata": {
    "language": "python",
    "name": "PreprocessData"
   },
   "outputs": [],
   "source": "# Extract numeric features\nfeature_cols = ['avg_transaction_amount', 'transactions_per_month', 'pct_weekend_transactions']\nX_features = df_pcard[feature_cols].copy()\n\n#show\nprint(f\"Features shape: {X_features.shape}\")\n\nX_features.describe()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "230615b8-d377-4b4c-af55-4876978e5a46",
   "metadata": {
    "language": "python",
    "name": "StandardizeFeatures"
   },
   "outputs": [],
   "source": "#standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_features)\n\n#build scaled data frame\ndf_scaled = pd.DataFrame(X_scaled, columns=feature_cols)\n\n#show\nprint(\"Features after scaling:\")\n\ndf_scaled.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9909504a-1315-4b0a-b96c-7e0f5449c85c",
   "metadata": {
    "language": "python",
    "name": "KDistance"
   },
   "outputs": [],
   "source": "#create k-distance plot\nmin_samples_value = 4\n\n#find nearest neighbors\nneighbors_model = NearestNeighbors(n_neighbors=min_samples_value)\nneighbors_fit = neighbors_model.fit(X_scaled)\n\n#find distances\ndistances, indices = neighbors_fit.kneighbors(X_scaled)\ndistances_sorted = np.sort(distances[:, min_samples_value-1], axis=0)[::-1]\n\n#build the plot\nplt.figure(figsize=(10, 6))\nplt.plot(distances_sorted, linewidth=2, color='steelblue')\nplt.xlabel('Data Points (sorted by distance)', fontsize=12)\nplt.ylabel('Distance to 4th Nearest Neighbor', fontsize=12)\nplt.title('K-Distance Plot for Epsilon Selection (min_samples=4)', fontsize=14)\nplt.grid(True, alpha=0.3)\n\n#plot for each eps candidate\nfor eps_candidate in [0.3, 0.5, 0.7, 1.0]:\n    plt.axhline(y=eps_candidate, color='red', linestyle='--', alpha=0.5, label=f'eps={eps_candidate}')\n\n#show\nplt.legend()\nplt.show()\n\n#show conclusion of eps value determination\nprint(f\"Suggested eps values:\")\nprint(f\"25th percentile: {np.percentile(distances_sorted, 25):.3f}\")\nprint(f\"50th percentile: {np.percentile(distances_sorted, 50):.3f}\")\nprint(f\"75th percentile: {np.percentile(distances_sorted, 75):.3f}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d54f5fd-3c39-4644-8c34-18e5d063bbba",
   "metadata": {
    "language": "python",
    "name": "ParameterExploration"
   },
   "outputs": [],
   "source": "#test multiple parameter combinations\neps_values = [0.3, 0.5, 0.7, 1.0]\nmin_samples_values = [3, 4, 5, 6]\n\n#build a list of results across min sample values (above)\nresults_list = []\n\nfor eps_value in eps_values:\n    for min_samples_value in min_samples_values:\n        dbscan_model = DBSCAN(eps=eps_value, min_samples=min_samples_value)\n        cluster_labels = dbscan_model.fit_predict(X_scaled)\n        \n        num_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n        num_noise = list(cluster_labels).count(-1)\n        pct_noise = (num_noise / len(cluster_labels)) * 100\n        \n        results_list.append({\n            'eps': eps_value,\n            'min_samples': min_samples_value,\n            'num_clusters': num_clusters,\n            'num_noise': num_noise,\n            'pct_noise': pct_noise\n        })\n\ndf_param_results = pd.DataFrame(results_list)\n\n#show the created list of eps values\nprint(\"Parameter Exploration Results:\")\n\ndf_param_results",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8daaa065-d5a4-4e56-b576-9203f834cdb0",
   "metadata": {
    "language": "python",
    "name": "VisualParameterExploration"
   },
   "outputs": [],
   "source": "#visualize parameter exploration\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n#build the data to plot\nfor min_samp in min_samples_values:\n    df_subset = df_param_results[df_param_results['min_samples'] == min_samp]\n    axes[0].plot(df_subset['eps'], df_subset['num_clusters'], marker='o', label=f'min_samples={min_samp}')\n\n#build the plots\naxes[0].set_xlabel('eps', fontsize=12)\naxes[0].set_ylabel('Number of Clusters', fontsize=12)\naxes[0].set_title('Effect of Parameters on Cluster Count', fontsize=14)\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\nfor min_samp in min_samples_values:\n    df_subset = df_param_results[df_param_results['min_samples'] == min_samp]\n    axes[1].plot(df_subset['eps'], df_subset['pct_noise'], marker='o', label=f'min_samples={min_samp}')\n\n#setup plots\naxes[1].set_xlabel('eps', fontsize=12)\naxes[1].set_ylabel('Percentage Noise Points', fontsize=12)\naxes[1].set_title('Effect of Parameters on Noise Detection', fontsize=14)\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\n#show\nplt.tight_layout()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2cca7ba-c727-4e9f-8d0f-74cd9f528cd5",
   "metadata": {
    "language": "python",
    "name": "FinalDBSCANModel"
   },
   "outputs": [],
   "source": "#select optimal parameters\noptimal_eps = 0.5\noptimal_min_samples = 4\n\nprint(f\"Running DBSCAN with eps={optimal_eps} and min_samples={optimal_min_samples}\")\n\n#fit final model - woohoo!\ndbscan_final = DBSCAN(eps=optimal_eps, min_samples=optimal_min_samples)\nfinal_cluster_labels = dbscan_final.fit_predict(X_scaled)\n\n#setup\ndf_pcard['cluster_label'] = final_cluster_labels\n\n#show\nprint(f\"Clustering complete!\")\nprint(f\"Unique cluster labels: {sorted(df_pcard['cluster_label'].unique())}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e578cac-a4a7-4119-9a56-33f2721564d9",
   "metadata": {
    "language": "python",
    "name": "AnalyzeResults"
   },
   "outputs": [],
   "source": "#count clusters and noise\nnum_clusters_final = len(set(final_cluster_labels)) - (1 if -1 in final_cluster_labels else 0)\nnum_noise_final = list(final_cluster_labels).count(-1)\npct_noise_final = (num_noise_final / len(final_cluster_labels)) * 100\n\n#show results\nprint(f\"Number of clusters: {num_clusters_final}\")\nprint(f\"Number of outliers: {num_noise_final}\")\nprint(f\"Percentage of outliers: {pct_noise_final:.2f}%\")\nprint(f\"\\nCluster distribution:\")\n\ndf_pcard['cluster_label'].value_counts().sort_index()\n\n#compute mean values per cluster\ncluster_means = (\n    df_pcard\n    .groupby('cluster_label')[feature_cols]\n    .mean()\n    .round(2)\n)\n\n#show cluster mean values\nprint(\"Mean values by cluster:\")\ncluster_means\n\n#create cluster summary\ncluster_summary = (\n    df_pcard\n    .groupby('cluster_label')\n    .agg({\n        'cardholder_id': 'count',\n        'avg_transaction_amount': 'mean',\n        'transactions_per_month': 'mean',\n        'pct_weekend_transactions': 'mean'\n    })\n    .rename(columns={'cardholder_id': 'count'})\n    .round(2)\n)\n\n#show summary of cluster findings\ncluster_summary['pct_of_total'] = ((cluster_summary['count'] / len(df_pcard)) * 100).round(2)\n\nprint(\"Detailed cluster summary:\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67adce1d-af74-4835-8bf9-8d1b7392d7a4",
   "metadata": {
    "language": "python",
    "name": "VisualizeClusters"
   },
   "outputs": [],
   "source": "#create several 2D scatterplots\n\n#setup\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nunique_labels = sorted(df_pcard['cluster_label'].unique())\ncolors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\ncolor_dict = {label: colors[i] if label != -1 else 'red' for i, label in enumerate(unique_labels)}\n\n#average transaction amount, by month\nfor label in unique_labels:\n    mask = df_pcard['cluster_label'] == label\n    label_name = 'Outliers' if label == -1 else f'Cluster {label}'\n    axes[0].scatter(\n        df_pcard.loc[mask, 'avg_transaction_amount'],\n        df_pcard.loc[mask, 'transactions_per_month'],\n        c=[color_dict[label]],\n        label=label_name,\n        alpha=0.7,\n        s=80,\n        edgecolors='black',\n        linewidth=0.5\n    )\n\naxes[0].set_xlabel('Average Transaction Amount ($)', fontsize=11)\naxes[0].set_ylabel('Transactions per Month', fontsize=11)\naxes[0].set_title('Spending Amount vs Frequency', fontsize=12)\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n#let's also look at weekend transactions (biz car usage on weekends!)\nfor label in unique_labels:\n    mask = df_pcard['cluster_label'] == label\n    label_name = 'Outliers' if label == -1 else f'Cluster {label}'\n    axes[1].scatter(\n        df_pcard.loc[mask, 'transactions_per_month'],\n        df_pcard.loc[mask, 'pct_weekend_transactions'],\n        c=[color_dict[label]],\n        label=label_name,\n        alpha=0.7,\n        s=80,\n        edgecolors='black',\n        linewidth=0.5\n    )\n\naxes[1].set_xlabel('Transactions per Month', fontsize=11)\naxes[1].set_ylabel('Pct Weekend Transactions', fontsize=11)\naxes[1].set_title('Frequency vs Weekend Usage', fontsize=12)\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\n#overall summary\nfor label in unique_labels:\n    mask = df_pcard['cluster_label'] == label\n    label_name = 'Outliers' if label == -1 else f'Cluster {label}'\n    axes[2].scatter(\n        df_pcard.loc[mask, 'avg_transaction_amount'],\n        df_pcard.loc[mask, 'pct_weekend_transactions'],\n        c=[color_dict[label]],\n        label=label_name,\n        alpha=0.7,\n        s=80,\n        edgecolors='black',\n        linewidth=0.5\n    )\n\naxes[2].set_xlabel('Average Transaction Amount ($)', fontsize=11)\naxes[2].set_ylabel('Pct Weekend Transactions', fontsize=11)\naxes[2].set_title('Amount vs Weekend Usage', fontsize=12)\naxes[2].legend()\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b2f24a7-3f30-493c-b458-00ea2c09a830",
   "metadata": {
    "language": "python",
    "name": "ThreeDClusters"
   },
   "outputs": [],
   "source": "#let's look at 3D visualization of the clusters\n#  (seemed worth a try)\nfig = plt.figure(figsize=(14, 10))\nax = fig.add_subplot(111, projection='3d')\n\n#build the labels\nfor label in unique_labels:\n    mask = df_pcard['cluster_label'] == label\n    label_name = 'Outliers' if label == -1 else f'Cluster {label}'\n    \n    ax.scatter(\n        df_pcard.loc[mask, 'avg_transaction_amount'],\n        df_pcard.loc[mask, 'transactions_per_month'],\n        df_pcard.loc[mask, 'pct_weekend_transactions'],\n        c=[color_dict[label]],\n        label=label_name,\n        alpha=0.7,\n        s=80,\n        edgecolors='black',\n        linewidth=0.5\n    )\n\n#setup\nax.set_xlabel('Avg Transaction Amount ($)', labelpad=10, fontsize=11)\nax.set_ylabel('Transactions per Month', labelpad=10, fontsize=11)\nax.set_zlabel('Pct Weekend Transactions', labelpad=10, fontsize=11)\nax.set_title('3D Cluster Visualization', fontsize=14, pad=20)\nax.legend(loc='upper right')\n\n#show\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed2e6dcc-0d14-49d1-81f4-fd04887468b4",
   "metadata": {
    "language": "python",
    "name": "ExamineOutliers"
   },
   "outputs": [],
   "source": "#identify outliers\n#in this data, the answer is in the outliers, not the clusters\n#  (we had a clue from class)\ndf_outliers = df_pcard[df_pcard['cluster_label'] == -1].copy()\n\nprint(f\"Number of outlier cardholders: {len(df_outliers)}\")\nprint(f\"\\nOutlier cardholder details:\")\n\n#compare outliers to typical spending\ndf_typical = df_pcard[df_pcard['cluster_label'] != -1].copy()\n\ncomparison_dict = {\n    'metric': feature_cols,\n    'typical_mean': [df_typical[col].mean() for col in feature_cols],\n    'outlier_mean': [df_outliers[col].mean() if len(df_outliers) > 0 else None for col in feature_cols],\n    'typical_std': [df_typical[col].std() for col in feature_cols],\n    'outlier_std': [df_outliers[col].std() if len(df_outliers) > 0 else None for col in feature_cols]\n}\n\n#compare\ndf_comparison = pd.DataFrame(comparison_dict).round(2)\n\nprint(\"Comparison of typical vs outlier spending:\")\ndf_comparison\n\n#create outlier flag using .map()\ndf_pcard['outlier_flag'] = df_pcard['cluster_label'].map(lambda x: 'Outlier' if x == -1 else 'Typical')\n\n#box plots comparing outliers to typical\n#same method as established above\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\ndf_pcard.boxplot(column='avg_transaction_amount', by='outlier_flag', ax=axes[0])\naxes[0].set_title('Average Transaction Amount')\naxes[0].set_xlabel('Cardholder Type')\naxes[0].set_ylabel('Amount ($)')\n\ndf_pcard.boxplot(column='transactions_per_month', by='outlier_flag', ax=axes[1])\naxes[1].set_title('Transactions per Month')\naxes[1].set_xlabel('Cardholder Type')\naxes[1].set_ylabel('Count')\n\ndf_pcard.boxplot(column='pct_weekend_transactions', by='outlier_flag', ax=axes[2])\naxes[2].set_title('Weekend Transaction Percent')\naxes[2].set_xlabel('Cardholder Type')\naxes[2].set_ylabel('Percentage')\n\n#show\nplt.suptitle('Outlier vs Typical Spending Comparison', y=1.02, fontsize=14)\nplt.tight_layout()\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0d8f01d-1019-441a-9f01-8bafd3759882",
   "metadata": {
    "language": "python",
    "name": "Interpretation"
   },
   "outputs": [],
   "source": "#analyze department representation\n#for a closer look at where problems may lie\nprint(\"Department distribution among outliers:\")\nprint(df_outliers['department'].value_counts())\nprint(\"\\nDepartment distribution among typical cardholders:\")\nprint(df_typical['department'].value_counts())\n\n#calculate department-level outlier rates\ndept_outlier_rate = (\n    df_pcard\n    .groupby('department')['outlier_flag']\n    .apply(lambda x: (x == 'Outlier').sum() / len(x) * 100)\n    .round(2)\n    .sort_values(ascending=False)\n)\n\n#show\nprint(\"Outlier rate by department:\")\ndept_outlier_rate",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7f6cf988-69c5-47e2-8aed-3d11437a7467",
   "metadata": {
    "name": "KeyFindings",
    "collapsed": false
   },
   "source": "## Key Findings\n\n### Typical Spending Clusters\n\nI start with a normal cluster analysis, identifying typical P-Card spending patterns which can be identified by examining the non-outlier clusters. These clusters represent cardholders with:\n\n- **Moderate transaction amounts**: Average transaction values within expected ranges for government purchases\n- **Consistent monthly activity**: Regular transaction frequency patterns\n- **Standard weekend usage**: Weekend transaction percentages aligned with normal needs\n\n### Outlier Cardholders (a focus of this data)\n\nOutliers (`cluster_label = -1`) represent cardholders whose spending patterns deviate significantly from typical behavior. These anomalies may warrant additional consideration for:\n\n**There may be some otential legitimate reasons, such as:**\n- Larger projects requiring larger purchases\n- Emergency or time-sensitive procurement needs\n- Specialized roles with unique purchasing requirements\n- Field operations requiring weekend transactions (think: emergencies)\n\n**Potential misuse indicators:**\n- Unusually high weekend transaction percentages (personal use?)\n- Higher average transaction amounts without justification\n- Anomalistic transaction frequency\n- Combinations of unusual patterns across multiple dimensions\n\n### Recommendations\n\n1. **Immediate review**: Conduct detailed audits of identified outlier cardholders\n2. **Department analysis**: Investigate departments with higher outlier rates\n3. **Policy review**: Evaluate whether spending policies need clarification\n4. **Ongoing monitoring**: Implement regular DBSCAN analysis for continuous anomaly detection\n5. **Context gathering**: Interview outlier cardholders to understand legitimate business justifications\n\n---\n\n### Summary\n\nDBSCAN clustering successfully identified natural groupings in P-Card spending behavior and flagged outliers for further investigation. The combination of `avg_transaction_amount`, `transactions_per_month`, and `pct_weekend_transactions` provides a robust multi-dimensional view of spending patterns. Regular application of this analysis can help the Office of the Inspector General proactively identify potential waste or misuse before it becomes a larger issue."
  }
 ]
}