{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "4kupkslwkm5wq7kzrbht",
   "authorId": "1043139642183",
   "authorName": "GASULLIVAN",
   "authorEmail": "sullivangregorya@wustl.edu",
   "sessionId": "8a1efb87-e7f8-4303-a0cc-a456b3b7496d",
   "lastEditTime": 1757384082092
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50433ee8-0e32-4322-81a1-a591bc690185",
   "metadata": {
    "name": "Section1Description",
    "collapsed": false
   },
   "source": "Section 1: Using SQL and Python in Snowflake\n1.\tAdd the Sample Movie Rental Database from Planet Data to your Snowflake account using the Snowflake Marketplace\n2.\tWrite a query to return a dataset with film and rental, and payment information. Your dataset should have multiple rows per film, one for each time the film was rented and the amount spent on each rental. Create a dataframe with this information\n3.\tCreate a dataframe from the customer table\n"
  },
  {
   "cell_type": "code",
   "id": "2cf227b1-65ed-49b0-a8db-710c2cb864a1",
   "metadata": {
    "language": "sql",
    "name": "Section1SQL"
   },
   "outputs": [],
   "source": "-- starting with a SQL query to build the dataset from which we'll conduct all our base analytics\n\nUSE DATABASE MOVIES_5740;\nUSE SCHEMA PUBLIC;\n\nWITH payment_per_rental AS (\n  SELECT\n      rental_id,\n      SUM(amount) AS amount_spent\n  FROM PAYMENT\n  GROUP BY rental_id\n)\nSELECT\n    f.film_id,\n    f.title,\n    f.description,\n    i.inventory_id,\n    r.rental_id,\n    r.rental_date,\n    r.return_date,\n    p.amount_spent,\n    pay.customer_id\nFROM FILM f\nJOIN INVENTORY i\n  ON i.film_id = f.film_id\nJOIN RENTAL r\n  ON r.inventory_id = i.inventory_id\nLEFT JOIN payment_per_rental p\n  ON p.rental_id = r.rental_id\nLEFT JOIN PAYMENT pay\n  ON pay.rental_id = r.rental_id\nORDER BY f.title, r.rental_date, r.rental_id;\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b020d41-e112-4f24-9125-a0a04b7cf1b8",
   "metadata": {
    "language": "python",
    "name": "Section1Python"
   },
   "outputs": [],
   "source": "# Next, conduct the same query from within Python so we can move our dataset in a Pandas dataframe\n\nfrom snowflake.snowpark.context import get_active_session\n\n# Get the injected Snowpark session for this notebook\nsession = get_active_session()\n\n\nsession.sql(\"USE DATABASE MOVIES_5740\").collect()\nsession.sql(\"USE SCHEMA PUBLIC\").collect()\n\n# Same SQL statement as above\nfilm_rentals_sp = session.sql(\"\"\"\nWITH payment_per_rental AS (\n    SELECT\n        rental_id,\n        SUM(amount) AS amount_spent\n    FROM PAYMENT\n    GROUP BY rental_id\n)\nSELECT\n    f.film_id,\n    f.title,\n    f.description,\n    r.rental_id,\n    r.rental_date,\n    r.return_date,\n    p.amount_spent\nFROM FILM f\nJOIN INVENTORY i\n    ON i.film_id = f.film_id\nJOIN RENTAL r\n    ON r.inventory_id = i.inventory_id\nLEFT JOIN payment_per_rental p\n    ON p.rental_id = r.rental_id\nORDER BY f.title, r.rental_date\n\"\"\")\n\n#create the Pandas dataframe from this query\nfilm_rentals_df = film_rentals_sp.to_pandas()\nprint(film_rentals_df.head(10))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bdde1bf1-65ac-4d90-878f-85cf62f9701c",
   "metadata": {
    "language": "python",
    "name": "Section1Q3"
   },
   "outputs": [],
   "source": "# Create a customer dataframe\n\nfrom snowflake.snowpark.context import get_active_session\n\n# Get the active Snowpark session\nsession = get_active_session()\n\n# Create a Snowpark DataFrame for the CUSTOMER table\ncustomers_sp = session.table(\"CUSTOMER\")\n\n# Convert to Pandas\ncustomers_df = customers_sp.to_pandas()\n\n# Preview first 10 rows\nprint(customers_df.head(10))\nprint(f\"Rows: {len(customers_df):,}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e798080a-fe50-4a66-af9e-1872228f9e05",
   "metadata": {
    "name": "Section2Description",
    "collapsed": false
   },
   "source": "Section 2: Manipulating dataframes\n1.\tCreate a column for customer name that has the first name and last name in the same column. \n2.\tRemove any inactive customers from the dataframe\nHint: use the active field\n3.\tChange the email addresses to be ‘joe.person@wustl.edu’, but only when their store_id is an even number\nHint: use apply to run a function over the dataframe, don’t forget to select the correct axis\n"
  },
  {
   "cell_type": "code",
   "id": "28ecef27-8fb7-4089-a130-e165de57db78",
   "metadata": {
    "language": "sql",
    "name": "Section2SQL"
   },
   "outputs": [],
   "source": "-- First, create the SQL query to see if we have it right, with the appropriate JOINs for building the desired table\nWITH payment_per_rental AS (\n    SELECT\n        rental_id,\n        SUM(amount) AS amount_spent\n    FROM PAYMENT\n    GROUP BY rental_id\n)\nSELECT\n    f.film_id,\n    f.title,\n    f.description,\n    f.mpaa_rating,\n    f.rental_rate,\n    i.inventory_id,\n    r.rental_id,\n    r.rental_date,\n    r.return_date,\n    p.amount_spent,\n    c.customer_id,\n    c.first_name,\n    c.last_name,\n    c.active,\n    c.email,\n    c.store_id\nFROM FILM f\nJOIN INVENTORY i\n    ON i.film_id = f.film_id\nJOIN RENTAL r\n    ON r.inventory_id = i.inventory_id\nJOIN PAYMENT pay\n    ON pay.rental_id = r.rental_id\nJOIN CUSTOMER c\n    ON c.customer_id = pay.customer_id\nLEFT JOIN payment_per_rental p\n    ON p.rental_id = r.rental_id\nORDER BY f.title, r.rental_date, r.rental_id;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8bd53410-02a3-4978-b58d-eadb508cca6a",
   "metadata": {
    "language": "python",
    "name": "Section2Python"
   },
   "outputs": [],
   "source": "# Next, in Python, use the query from above (that we tested) to create the dataset we desired, then put it into a Pandas dataframe.\n# We'll also create the customer name column by putting the first name before the last name\n# Then, we'll go through again and remove all the inactive customeers by checking if the ACTIVE column is inactive (value 0).  \n#   Otherwise, we assume active.\n\nfrom snowflake.snowpark.context import get_active_session\n\n# Get active Snowpark session\nsession = get_active_session()\n\n# Define the SQL string (triple quotes let us write multi-line SQL)\nsql_query = \"\"\"\nWITH payment_per_rental AS (\n    SELECT\n        rental_id,\n        SUM(amount) AS amount_spent\n    FROM PAYMENT\n    GROUP BY rental_id\n)\nSELECT\n    f.film_id,\n    f.title,\n    f.description,\n    f.mpaa_rating,\n    f.rental_rate,\n    i.inventory_id,\n    r.rental_id,\n    r.rental_date,\n    r.return_date,\n    p.amount_spent,\n    c.customer_id,\n    c.first_name,\n    c.last_name,\n    c.active,\n    c.email,\n    c.store_id\nFROM FILM f\nJOIN INVENTORY i\n    ON i.film_id = f.film_id\nJOIN RENTAL r\n    ON r.inventory_id = i.inventory_id\nJOIN PAYMENT pay\n    ON pay.rental_id = r.rental_id\nJOIN CUSTOMER c\n    ON c.customer_id = pay.customer_id\nLEFT JOIN payment_per_rental p\n    ON p.rental_id = r.rental_id\nORDER BY f.title, r.rental_date, r.rental_id\n\"\"\"\n\n# Run the SQL and convert to Pandas\nfilm_rentals_df = session.sql(sql_query).to_pandas()\n\n# Create a combined customer_name column\nfilm_rentals_df[\"CUSTOMER_NAME\"] = (\n    film_rentals_df[\"FIRST_NAME\"] + \" \" + film_rentals_df[\"LAST_NAME\"]\n)\n\n# Preview results\nprint(film_rentals_df[[\"TITLE\", \"CUSTOMER_ID\", \"FIRST_NAME\", \"LAST_NAME\", \"CUSTOMER_NAME\"]].head(10))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43890ddd-edac-4874-b54b-d8ef7b07b2a9",
   "metadata": {
    "language": "python",
    "name": "Section2PythonContinued"
   },
   "outputs": [],
   "source": "# Include only active customers (ACTIVE column is 1)\n# Keep only rows where ACTIVE == 1\nfilm_rentals_active_df = film_rentals_df[film_rentals_df[\"ACTIVE\"] == 1]\n\n# Preview\nprint(film_rentals_active_df.head(10))\nprint(f\"Rows after filtering: {len(film_rentals_active_df):,}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc54e04f-ab05-4aaf-aadb-263ea7cf9497",
   "metadata": {
    "language": "python",
    "name": "Section2PythonContinuedAgain"
   },
   "outputs": [],
   "source": "# Change the email addresses to be ‘joe.person@wustl.edu’,\n#   but only when their store_id is an even number \n#   Hint: use apply to run a function over the dataframe, don’t forget to select the correct axis\n\n#define a function that replaces the e-mail address, but only if the store_id is an even number (modulus zero)\ndef replace_email(row):\n    if row[\"STORE_ID\"] % 2 == 0:         # even store_id\n        return \"joe.person@wustl.edu\"\n    else:\n        return row[\"EMAIL\"]              # keep the original\n\n#apply the function across the entire dataframe, but do it for the rows (axis is 1)\nfilm_rentals_df[\"EMAIL\"] = film_rentals_df.apply(replace_email, axis=1)\n\n#quick check to see if we did it right\nprint(film_rentals_df[[\"CUSTOMER_ID\", \"STORE_ID\", \"EMAIL\"]].head(10))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6661b8e-e275-4d11-9a03-0a841ba90f62",
   "metadata": {
    "language": "python",
    "name": "Section2PythonCustomerDF"
   },
   "outputs": [],
   "source": "# also do the e-mail address change in the customer dataframe\ndef replace_email(row):\n    if row[\"STORE_ID\"] % 2 == 0:        # even store_id\n        return \"joe.person@wustl.edu\"\n    else:\n        return row[\"EMAIL\"]\n\ncustomers_df[\"EMAIL\"] = customers_df.apply(replace_email, axis=1)\nprint(customers_df[[\"CUSTOMER_ID\", \"STORE_ID\", \"EMAIL\"]].head(10))\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59981278-9239-40ab-8218-236ed5557c6d",
   "metadata": {
    "name": "Section3Description",
    "collapsed": false
   },
   "source": "Section 3: Visualizations\n1.\tHow much does each customer tend to spend in aggregate?\nClarification: You want to first create total spend by customer, then you want to visualize that distribution, each customer being an observation. A box and whisker plot would be a good visualization\n2.\tWhat does the distribution of film revenue look like?\nClarification: You want to first calculate the revenue by film, you can sum the rental rate for each instance that the film was rented using the dataframe you created in section 1 part 2. A histogram would be a good visualization\n"
  },
  {
   "cell_type": "code",
   "id": "4a344d7f-44bc-4cf0-8a25-546aaacca00e",
   "metadata": {
    "language": "python",
    "name": "Section3Python"
   },
   "outputs": [],
   "source": "# Group by customer and calculate total spend\ncustomer_spend_df = (\n    film_rentals_df.groupby(\"CUSTOMER_ID\")[\"AMOUNT_SPENT\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"AMOUNT_SPENT\": \"TOTAL_SPEND\"})\n)\n\nprint(customer_spend_df.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d03c6584-7c6b-4814-aba8-052d0a4d5645",
   "metadata": {
    "language": "python",
    "name": "Section3PythonContinued"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\n# Aggregate spend per customer\ncustomer_spend_df = (\n    film_rentals_df.groupby(\"CUSTOMER_ID\")[\"AMOUNT_SPENT\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"AMOUNT_SPENT\": \"TOTAL_SPEND\"})\n)\n\n# Plot box and whisker\nplt.figure(figsize=(8,6))\nplt.boxplot(customer_spend_df[\"TOTAL_SPEND\"], vert=True, patch_artist=True)\n\nplt.title(\"Distribution of Total Spend per Customer\")\nplt.ylabel(\"Total Spend ($)\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n\n# This ensures the chart renders in Snowflake Notebooks / Jupyter\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0113dd1e-733d-4047-91d3-091dd8596a6f",
   "metadata": {
    "language": "python",
    "name": "Section3PythonAgain"
   },
   "outputs": [],
   "source": "# Aggregate total revenue by film\nfilm_revenue_df = (\n    film_rentals_df.groupby([\"FILM_ID\", \"TITLE\"])[\"AMOUNT_SPENT\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"AMOUNT_SPENT\": \"TOTAL_REVENUE\"})\n)\n\nprint(film_revenue_df.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dff7590a-772e-494b-988a-b5b9c07b673b",
   "metadata": {
    "language": "python",
    "name": "Section3PythonPlot"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\n# generate a bar chart of the revenue/film by counting the number of films\nplt.figure(figsize=(10,6))\nplt.hist(film_revenue_df[\"TOTAL_REVENUE\"], bins=30, edgecolor=\"black\")\n\nplt.title(\"Distribution of Total Film Revenue\")\nplt.xlabel(\"Total Revenue per Film ($)\")\nplt.ylabel(\"Number of Films\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "08e78886-1a13-4ca4-abc2-d7e36ecffd4b",
   "metadata": {
    "name": "Section4Description",
    "collapsed": false
   },
   "source": "Section 4: Analysis\nClarification: You do not need to use a statistical test to answer the following questions. Please use a visualization and interpret what see. Note the averages, counts, or sums where applicable, and the interpretation\n1.\tOn average, is the rental rate the same across movie ratings, treat each film as an observation?\n2.\tAcross the various film ratings, are we observing the same number of movies rented at store 2 and store 1?\n3.\tOn average, do films with a character of a ‘robot’ generate the same amount of revenue (use rental rate) as films that feature a ‘teacher’?\nHint: sum the rental rate by film across rentals to get revenue by film\n"
  },
  {
   "cell_type": "code",
   "id": "a7d6a80d-2dc6-4b81-a51e-97e27a614d0e",
   "metadata": {
    "language": "python",
    "name": "Section4PythonQ1"
   },
   "outputs": [],
   "source": "# Each film is one observation → keep film_id, title, mpaa_rating, rental_rate\nfilm_rates_df = film_rentals_df.drop_duplicates(subset=[\"FILM_ID\"])[\n    [\"FILM_ID\", \"TITLE\", \"MPAA_RATING\", \"RENTAL_RATE\"]\n]\n\nprint(film_rates_df.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f586424-d131-48fe-b159-077e59f16291",
   "metadata": {
    "language": "python",
    "name": "Section4PythonQ1Avg"
   },
   "outputs": [],
   "source": "avg_rate_by_rating = (\n    film_rates_df.groupby(\"MPAA_RATING\")[\"RENTAL_RATE\"]\n    .mean()\n    .reset_index()\n    .rename(columns={\"RENTAL_RATE\": \"AVG_RENTAL_RATE\"})\n)\n\nprint(avg_rate_by_rating)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e677dee-6b23-453e-a477-88f81f76a782",
   "metadata": {
    "language": "python",
    "name": "Section4PythonQ1Visualize"
   },
   "outputs": [],
   "source": "#try a simple bar chart\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,6))\nplt.bar(avg_rate_by_rating[\"MPAA_RATING\"], avg_rate_by_rating[\"AVG_RENTAL_RATE\"], color=\"skyblue\", edgecolor=\"black\")\n\nplt.title(\"Average Rental Rate by Film Rating\")\nplt.xlabel(\"Film Rating\")\nplt.ylabel(\"Average Rental Rate ($)\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4fc98f95-786d-4bd9-8219-5d3b71a6f131",
   "metadata": {
    "name": "Section4PythonQ1Analysis",
    "collapsed": false
   },
   "source": "With my eyes, I do not see any significance to the impact of rating on rental rate.  In fact, it looks very evenly distributed.\n\nHowever, I want to assure it's not a visual trick of some sort.  So, I'll run an Analysis of Variance "
  },
  {
   "cell_type": "code",
   "id": "ec607d90-f371-4f5b-b5b8-e16429aa3a9c",
   "metadata": {
    "language": "python",
    "name": "Section4PythonAvgByRating"
   },
   "outputs": [],
   "source": "# One row per film (avoids duplicate rentals)\nfilm_rates_df = film_rentals_df.drop_duplicates(subset=[\"FILM_ID\"])[\n    [\"FILM_ID\", \"TITLE\", \"MPAA_RATING\", \"RENTAL_RATE\"]\n]\n\n#continue as before\navg_rate_by_rating = (\n    film_rates_df.groupby(\"MPAA_RATING\")[\"RENTAL_RATE\"]\n    .mean()\n    .reset_index()\n    .rename(columns={\"RENTAL_RATE\": \"AVG_RENTAL_RATE\"})\n)\n\nprint(avg_rate_by_rating)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc641e7a-628f-4721-a78c-3ca8f7b6694a",
   "metadata": {
    "language": "python",
    "name": "Section4PythonANOVA"
   },
   "outputs": [],
   "source": "# One row per film (avoids duplicate rentals)\nfilm_rates_df = film_rentals_df.drop_duplicates(subset=[\"FILM_ID\"])[\n    [\"FILM_ID\", \"TITLE\", \"MPAA_RATING\", \"RENTAL_RATE\"]\n]\n\n# run ANOVA with scipy\nfrom scipy.stats import f_oneway\n\n# Build a list of rental_rate values, one list per rating\ngroups = [\n    film_rates_df.loc[film_rates_df[\"MPAA_RATING\"] == rating, \"RENTAL_RATE\"].values\n    for rating in film_rates_df[\"MPAA_RATING\"].unique()\n]\n\n# Perform one-way ANOVA\nf_stat, p_val = f_oneway(*groups)\n\nprint(\"ANOVA F-statistic:\", f_stat)\nprint(\"p-value:\", p_val)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8467ba3a-5cbf-4369-8295-75c46a70e313",
   "metadata": {
    "name": "Section4PythonQ1Conclusion",
    "collapsed": false
   },
   "source": "p-value < 0.05 → statistically significant difference in average rental rates between at least one pair of ratings.\np-value ≥ 0.05 → no evidence that rental rates differ by rating (any variation is likely random).\n\nOur p-value is greater than 0.05 (much greater, in fact).  So, this confirms my visual observation from the bar chart above."
  },
  {
   "cell_type": "markdown",
   "id": "cd19655d-53eb-40ed-98de-2c1885b67eb3",
   "metadata": {
    "name": "Section4PythonQ2",
    "collapsed": false
   },
   "source": "Section 4: Analysis\nClarification: You do not need to use a statistical test to answer the following questions. Please use a visualization and interpret what see. Note the averages, counts, or sums where applicable, and the interpretation\n\n2.\tAcross the various film ratings, are we observing the same number of movies rented at store 2 and store 1?\n    \n"
  },
  {
   "cell_type": "code",
   "id": "bb4e4708-3f38-4916-9dd8-b6c77c644132",
   "metadata": {
    "language": "python",
    "name": "Section4PythonQ2Distribution"
   },
   "outputs": [],
   "source": "# Count number of rentals by rating and store\nrating_store_counts = (\n    film_rentals_df.groupby([\"MPAA_RATING\", \"STORE_ID\"])[\"RENTAL_ID\"]\n    .count()\n    .reset_index()\n    .rename(columns={\"RENTAL_ID\": \"RENTAL_COUNT\"})\n)\n\nprint(rating_store_counts.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57d5db1d-a83f-4d03-92df-f10f6232ea6b",
   "metadata": {
    "language": "python",
    "name": "Section4PythonQ2Visualize"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\npivot_counts = rating_store_counts.pivot(index=\"MPAA_RATING\", columns=\"STORE_ID\", values=\"RENTAL_COUNT\")\n\npivot_counts.plot(kind=\"bar\", figsize=(10,6))\n\nplt.title(\"Number of Rentals by Film Rating and Store\")\nplt.xlabel(\"Film Rating\")\nplt.ylabel(\"Number of Rentals\")\nplt.legend(title=\"Store\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c83bb00-ca9c-434b-b46e-6a722e9b4c59",
   "metadata": {
    "language": "python",
    "name": "Section4Q2Analyze"
   },
   "outputs": [],
   "source": "from scipy.stats import chi2_contingency\n\n# Build contingency table: rows = ratings, cols = stores\ncontingency_table = pivot_counts.fillna(0).astype(int)\n\nchi2, p, dof, expected = chi2_contingency(contingency_table)\n\nprint(\"Chi-square statistic:\", chi2)\nprint(\"p-value:\", p)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e07e9aa3-61e2-47a5-ab88-1f73986aa49f",
   "metadata": {
    "name": "Section4Q2Check",
    "collapsed": false
   },
   "source": "again, p-value is greater than 0.05, so we do not have a significant difference - which confirms our visual check (they look similar)"
  },
  {
   "cell_type": "markdown",
   "id": "c38cefb6-4905-4511-b0a8-2162b76a17ff",
   "metadata": {
    "name": "Section4Q3",
    "collapsed": false
   },
   "source": "3.\tOn average, do films with a character of a ‘robot’ generate the same amount of revenue (use rental rate) as films that feature a ‘teacher’?\nHint: sum the rental rate by film across rentals to get revenue by film\n"
  },
  {
   "cell_type": "code",
   "id": "837a1ce1-7139-4dd9-8cb9-67ac0059c298",
   "metadata": {
    "language": "python",
    "name": "Section4Q4RevenuePerFilm",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Step 1: revenue per film\nfilm_revenue_df = (\n    film_rentals_df.groupby([\"FILM_ID\", \"TITLE\", \"DESCRIPTION\"])[\"RENTAL_RATE\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"RENTAL_RATE\": \"TOTAL_REVENUE\"})\n)\n\nprint(film_revenue_df.head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "07170db3-c741-478e-b205-11544b27e062",
   "metadata": {
    "language": "python",
    "name": "Section4Q3RobotAndTeacher"
   },
   "outputs": [],
   "source": "# Make sure DESCRIPTION is a string and lowercase for consistent matching\nfilm_revenue_df[\"DESCRIPTION\"] = film_revenue_df[\"DESCRIPTION\"].astype(str).str.lower()\n\n# Create boolean flags\nfilm_revenue_df[\"HAS_ROBOT\"] = film_revenue_df[\"DESCRIPTION\"].str.contains(\"robot\", na=False)\nfilm_revenue_df[\"HAS_TEACHER\"] = film_revenue_df[\"DESCRIPTION\"].str.contains(\"teacher\", na=False)\n\n# Quick check of how many films match each\nprint(\"Robot films:\", film_revenue_df[\"HAS_ROBOT\"].sum())\nprint(\"Teacher films:\", film_revenue_df[\"HAS_TEACHER\"].sum())\n\n\nrobot_revenue = film_revenue_df.loc[film_revenue_df[\"HAS_ROBOT\"], \"TOTAL_REVENUE\"]\nteacher_revenue = film_revenue_df.loc[film_revenue_df[\"HAS_TEACHER\"], \"TOTAL_REVENUE\"]\n\nprint(\"Number of robot films:\", len(robot_revenue))\nprint(\"Number of teacher films:\", len(teacher_revenue))\n\nprint(\"Average robot film revenue: ${:,.2f}\".format(robot_revenue.mean()))\nprint(\"Average teacher film revenue: ${:,.2f}\".format(teacher_revenue.mean()))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e664337-9e11-425e-94b7-1e63efbc94da",
   "metadata": {
    "language": "python",
    "name": "Section3Q3Ttest"
   },
   "outputs": [],
   "source": "from scipy.stats import ttest_ind\n\nt_stat, p_val = ttest_ind(robot_revenue, teacher_revenue, equal_var=False)  # Welch’s t-test\nprint(\"t-statistic:\", t_stat)\nprint(\"p-value:\", p_val)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea713160-7a77-4689-a48b-30943c661e93",
   "metadata": {
    "name": "Section3Q3Analysis",
    "collapsed": false
   },
   "source": "There is no significant difference give the p-value is greater than 0.05"
  },
  {
   "cell_type": "markdown",
   "id": "4b8300dc-443e-4177-81c8-5678b6a8fe26",
   "metadata": {
    "name": "Section5Description",
    "collapsed": false
   },
   "source": "Section 5: Analysis\nIts late 2005, and your boss at the DVD rental company wants to know how effective his customer promotion program was. He tells you, ‘I want you to give me some descriptive information about how much the customers spent before and after the program started. Were the spending habits similar? Did they differ? Did the program help or make things worse?’\n1.\tWhat is the outcome?\n2.\tWhat is the main effect/predictor he wants to understand the impact of?\n3.\tWhat is the hypothesis?\nLucky for you, your boss already asked Ted in Bethesda to give you a query for how to get the information. \nQuery:\n        with b4 as (\n            select p.customer_id, sum(p.amount) as Payment_before\n            from rental r \n            left outer join payment p on p.rental_id = r.rental_id\n            where rental_date < cast('2005-07-01' as timestamp) and\n                amount is not null\n            group by p.customer_id),\n        aft as (\n            select p.customer_id, sum(p.amount) as Payment_after\n            from rental r \n            left outer join payment p on p.rental_id = r.rental_id\n            where rental_date >= cast('2005-07-01' as timestamp) and\n                amount is not null\n            group by p.customer_id\n        )\n        select distinct c.customer_id, store_id, first_name, last_name,\n            active, payment_before, payment_after\n        from customer c\n        left outer join b4 r on r.customer_id = c.customer_id\n        left outer join aft a on a.customer_id = c.customer_id\n        where payment_after is not null and payment_before is not null\nPlus, the statistician you work with has some suggestions for how to give your boss what he wants. Query the data from your container and put it in a Pandas dataframe. Then follow the statistician’s suggestions.\n4.\tCompute summary statistics and create histograms of the payment_before and payment_after variables. (Try using describe()in pandas).\n5.\tCompute the correlation between these two variables and create a scatterplot\n6.\tCompute a variable which is the difference between the amounts spent before and after the program started:  payment_after – payment_before. \n7.\tGenerate a histogram of the difference and conduct a one-sample t-test.\n8.\tInterpret your results\n"
  },
  {
   "cell_type": "code",
   "id": "fe391969-0fe5-4371-85ad-ba5b2382f690",
   "metadata": {
    "language": "sql",
    "name": "Section5Q3SQL"
   },
   "outputs": [],
   "source": "-- Query from the problem statement.\nwith b4 as ( select p.customer_id, sum(p.amount) as Payment_before from rental r left outer join payment p on p.rental_id = r.rental_id where rental_date < cast('2005-07-01' as timestamp) and amount is not null group by p.customer_id), aft as ( select p.customer_id, sum(p.amount) as Payment_after from rental r left outer join payment p on p.rental_id = r.rental_id where rental_date >= cast('2005-07-01' as timestamp) and amount is not null group by p.customer_id ) select distinct c.customer_id, store_id, first_name, last_name, active, payment_before, payment_after from customer c left outer join b4 r on r.customer_id = c.customer_id left outer join aft a on a.customer_id = c.customer_id where payment_after is not null and payment_before is not null",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f01088e4-5a16-4e61-a0df-399ce87e422e",
   "metadata": {
    "language": "python",
    "name": "Section5Q3Python"
   },
   "outputs": [],
   "source": "# now, repeat the query, but in Python so we can create a Pandas __DataFrame__\n\nfrom snowflake.snowpark.context import get_active_session\n\n# Get the active Snowpark session\nsession = get_active_session()\n\n# Define your SQL query\nsql_query = \"\"\"\nWITH b4 AS (\n    SELECT \n        p.customer_id, \n        SUM(p.amount) AS payment_before\n    FROM rental r \n    LEFT OUTER JOIN payment p \n        ON p.rental_id = r.rental_id\n    WHERE rental_date < CAST('2005-07-01' AS TIMESTAMP)\n      AND amount IS NOT NULL\n    GROUP BY p.customer_id\n), \naft AS (\n    SELECT \n        p.customer_id, \n        SUM(p.amount) AS payment_after\n    FROM rental r \n    LEFT OUTER JOIN payment p \n        ON p.rental_id = r.rental_id\n    WHERE rental_date >= CAST('2005-07-01' AS TIMESTAMP)\n      AND amount IS NOT NULL\n    GROUP BY p.customer_id\n)\nSELECT DISTINCT \n    c.customer_id, \n    c.store_id, \n    c.first_name, \n    c.last_name, \n    c.active, \n    r.payment_before, \n    a.payment_after\nFROM customer c\nLEFT OUTER JOIN b4 r \n    ON r.customer_id = c.customer_id\nLEFT OUTER JOIN aft a \n    ON a.customer_id = c.customer_id\nWHERE payment_after IS NOT NULL \n  AND payment_before IS NOT NULL\n\"\"\"\n\n# Run the query and convert to Pandas\npayments_df = session.sql(sql_query).to_pandas()\n\n# Preview results\nprint(payments_df.head())\nprint(f\"Rows: {len(payments_df):,}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f742bda0-3ee9-45f8-a196-5f5b1e2ea652",
   "metadata": {
    "language": "python",
    "name": "Section5Q4PythonPart1"
   },
   "outputs": [],
   "source": "# Summary statistics for before/after payments\nprint(\"Summary statistics:\\n\")\nprint(payments_df[[\"PAYMENT_BEFORE\", \"PAYMENT_AFTER\"]].describe())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0fd9d9dc-8d95-4dac-b288-142a462a9798",
   "metadata": {
    "language": "python",
    "name": "Section5Q4PythonPart2"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,5))\n\n# Histogram: payment_before\nplt.subplot(1,2,1)\nplt.hist(payments_df[\"PAYMENT_BEFORE\"].dropna(), bins=30, edgecolor=\"black\")\nplt.title(\"Distribution of Payments Before July 2005\")\nplt.xlabel(\"Total Payment Before\")\nplt.ylabel(\"Number of Customers\")\n\n# Histogram: payment_after\nplt.subplot(1,2,2)\nplt.hist(payments_df[\"PAYMENT_AFTER\"].dropna(), bins=30, edgecolor=\"black\")\nplt.title(\"Distribution of Payments After July 2005\")\nplt.xlabel(\"Total Payment After\")\nplt.ylabel(\"Number of Customers\")\n\nplt.tight_layout()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3685fcc7-3a74-4298-82d1-02a3e9a79a1b",
   "metadata": {
    "language": "python",
    "name": "Section5Q5Python"
   },
   "outputs": [],
   "source": "# Compute the correlation between these two variables and create a scatterplot\n# Correlation matrix\ncorr = payments_df[[\"PAYMENT_BEFORE\", \"PAYMENT_AFTER\"]].corr()\n\nprint(\"Correlation between payment_before and payment_after:\")\nprint(corr)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62b20325-5785-468e-9972-f904d9174ff3",
   "metadata": {
    "language": "python",
    "name": "Section5Q5Visualize"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(7,6))\nplt.scatter(\n    payments_df[\"PAYMENT_BEFORE\"],\n    payments_df[\"PAYMENT_AFTER\"],\n    alpha=0.6, edgecolor=\"black\"\n)\n\nplt.title(\"Scatterplot of Payments Before vs After July 2005\")\nplt.xlabel(\"Payment Before (total per customer)\")\nplt.ylabel(\"Payment After (total per customer)\")\nplt.grid(True, linestyle=\"--\", alpha=0.7)\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c31fcd5c-7071-4599-a02f-c5a22b72e698",
   "metadata": {
    "language": "python",
    "name": "Section5Q6Python"
   },
   "outputs": [],
   "source": "# Compute a variable which is the difference between the amounts spent before and after the program started: payment_after – payment_before\n\n# Compute the difference\npayments_df[\"PAYMENT_DIFF\"] = payments_df[\"PAYMENT_AFTER\"] - payments_df[\"PAYMENT_BEFORE\"]\n\n# Quick preview\nprint(payments_df[[\"CUSTOMER_ID\", \"PAYMENT_BEFORE\", \"PAYMENT_AFTER\", \"PAYMENT_DIFF\"]].head())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e9db1bf-35b9-460c-a44c-c372b0614776",
   "metadata": {
    "language": "python",
    "name": "Section5Q7Python"
   },
   "outputs": [],
   "source": "# Generate a histogram of the difference and conduct a one-sample t-test\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,6))\nplt.hist(payments_df[\"PAYMENT_DIFF\"].dropna(), bins=30, edgecolor=\"black\")\nplt.title(\"Distribution of Payment Difference (After – Before)\")\nplt.xlabel(\"Difference in Payments\")\nplt.ylabel(\"Number of Customers\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44851a3e-d7b9-45df-8a3b-e3d66ad73dce",
   "metadata": {
    "language": "python",
    "name": "Section5Q7PythonTTest"
   },
   "outputs": [],
   "source": "from scipy.stats import ttest_1samp\n\ndiff_values = payments_df[\"PAYMENT_DIFF\"].dropna()\n\nt_stat, p_val = ttest_1samp(diff_values, popmean=0)\n\nprint(\"One-sample t-test for mean difference vs 0\")\nprint(\"t-statistic:\", t_stat)\nprint(\"p-value:\", p_val)\nprint(\"Average difference:\", diff_values.mean())",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bafb103c-e957-417f-bc55-d3b6fc66871d",
   "metadata": {
    "name": "Section5Q8Interpret",
    "collapsed": false
   },
   "source": "Interpret The Results:\n\nI arbitrarily drew the line at halfway through the year and assumed any impact from the program would've occured after July 1 of that year.  On average, the customers spent about $71.42 more after the program compared to before the program.  The t-test value of ~65 shows the difference is highly statistically significant.  This is a positive indication of the impact of the program and that the increased spending is very real, and not due to random chance.  Our conclusion is that the program had a strong positive impact on customer payments.\n\nFor a visual on this, see the above scatterplot which shows the movement \"up\" on the left side of the chart - indicating a greater spend after the program, than before. Furthermore, the distribution bar chart confirms a higher concentration of customer payment size after the program."
  }
 ]
}