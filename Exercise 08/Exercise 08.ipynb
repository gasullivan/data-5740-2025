{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "cuwdysx4jghomsxsjpnq",
   "authorId": "1043139642183",
   "authorName": "GASULLIVAN",
   "authorEmail": "sullivangregorya@wustl.edu",
   "sessionId": "87be711b-ed0c-4ba2-b437-ff91e8979dac",
   "lastEditTime": 1760995412488
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57080ff0-ac60-402d-b631-c19274352384",
   "metadata": {
    "name": "Preamble",
    "collapsed": false
   },
   "source": "Paul, this has been a great exercise for me and I'm eager for feedback.  I selected the cyber data set as this aligns perfectly with my day-to-day work and is a topic I am very passionate about.  One of the thoughts I've been having as we've worked through the semester: How do we know we've selected the best variables for building our models?  PCA seems to be the best answer I've seen so far.  In fact, it seems so incredible I wonder what could be better?  I'm sure there are more and better ways yet to learn, but this one sure seems to do the trick quite well.\n\nAlso, I tried to point out where I took different approaches with the cyber data the second time around.  It seemed the more I experimented with this PCA approach, the better the model helped me understand where to recommend we align our resources to be the most secure.  Admittedly, I ramble on toward the end of the notebook with multiple recommendation attempts (ignore anything after Conclusion if you like), but it seems there is always an answer just better than the last one, no matter how many times we adjust the approach."
  },
  {
   "cell_type": "markdown",
   "id": "f71f94a3-e65b-4845-b7c7-52eb9e38592b",
   "metadata": {
    "name": "Exercise08",
    "collapsed": false
   },
   "source": "# Exercise 08: Principal Component Analysis (PCA)\n\nPick from the data in one of our previous assignments or the midterm (agri_productivity.csv, **cybersec.csv**, midterm_construction_projects.csv). Conduct the same kind of PCA we did in the lab, focusing only on continuous variables.\n1.\tExplore the data\n2.\tStandardize the data so we can do PCA\n3.\tFit PCA and look at the explained variance \n4.\tProject the original data onto the necessary principal components\n5.\tExplain in detail what the PCA has told you about the data, given the principal components some intuitive meaning, and explain how you would use your insights from the PCA\n\nI have selected the cyber data set (Lab 05) on which to apply a Principal Component Analysis.  To start, I will repeat the steps in took in Lab 05 to load, analyze, clean, transform and check the data BEFORE I begin the PCA."
  },
  {
   "cell_type": "code",
   "id": "ca029474-4f1d-4458-b44a-8640a63d3c37",
   "metadata": {
    "language": "python",
    "name": "ImportPackages"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import skew\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import PCA as PCAModel",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "852ba6ea-5d26-4b10-9d8d-c3c4e3d958c6",
   "metadata": {
    "name": "DataFamiliarization",
    "collapsed": false
   },
   "source": "1.\tData Familiarization & Hygiene\n    a.\tInspect schema, ranges, and datatypes.\n    b.\tDetect and fix issues: missing values, impossible percentages, and text in numeric fields.\n    c.\tApply simple imputation and clipping strategies.\n"
  },
  {
   "cell_type": "code",
   "id": "d82958f9-8f6e-4d68-bd1f-e58acf62a07d",
   "metadata": {
    "language": "python",
    "name": "DataFamiliarizationCode"
   },
   "outputs": [],
   "source": "#load the csv into a data frame\n#perform some familiarization steps with the data set\n#inspect and display some meta/summary data about the data set\n\n#load CSV to pandas data frame\ncyber_df = pd.read_csv(\"cybersec.csv\")\n\n#inspect schema and types\nprint(\"Schema and Data Types:\\n\", cyber_df.dtypes, \"\\n\")\n\n#show summary statistics\nprint(\"Summary Statistics:\\n\", cyber_df.describe(include='all'), \"\\n\")\n\n#show missing values\nprint(\"Missing Values:\\n\", cyber_df.isnull().sum(), \"\\n\")\n\n#show some unique values for object columns\nobject_columns = cyber_df.select_dtypes(include=['object']).columns\nfor col in object_columns:\n    print(f\"{col} unique values:\", cyber_df[col].unique()[:10])\nprint()\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4119b111-ee70-4813-a727-9ffa57942bc6",
   "metadata": {
    "language": "python",
    "name": "DataCleanUp"
   },
   "outputs": [],
   "source": "#detect & fix issues\n#clip impossible % values, just in case\ncyber_df['phishing_sim_click_rate'] = cyber_df['phishing_sim_click_rate'].clip(upper=1.0)\n\n#fix text 'null' if present (not needed here, but included as good hygiene)\ncyber_df.replace(\"null\", pd.NA, inplace=True)\n\n#setup the missing values (mean)\ncyber_df['vuln_count'] = cyber_df['vuln_count'].fillna(cyber_df['vuln_count'].mean())\ncyber_df['training_completion_rate'] = cyber_df['training_completion_rate'].fillna(cyber_df['training_completion_rate'].mean())\n\n#check if all missing values handled\nprint(\"Post-cleaning Missing Values:\\n\", cyber_df.isnull().sum())\n\n#quick preview\ncyber_df.head()\n\n#actual column names\nprint(cyber_df.columns.tolist())\n\n#check the min and max values of the endpoint_coverage column\nmin_coverage = cyber_df['endpoint_coverage'].min()\nmax_coverage = cyber_df['endpoint_coverage'].max()\n\nprint(f\"Endpoint Coverage ranges from {min_coverage}% to {max_coverage}%.\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ba963232-53df-4c29-a470-3553c98256a2",
   "metadata": {
    "name": "EDA",
    "collapsed": false
   },
   "source": "2.\tExploratory Analysis (EDA)\n    a.\tPlot distributions (incidents histogram).\n    b.\tExplore relationships (incidents vs. vulnerabilities, patch time).\n    c.\tSpot skewness and potential transformations."
  },
  {
   "cell_type": "code",
   "id": "4222d51f-c0f4-4bf1-818d-ad49a04b172a",
   "metadata": {
    "language": "python",
    "name": "EDACode"
   },
   "outputs": [],
   "source": "#Histogram of Security Incidents\n\nplt.figure(figsize=(8, 5))\nsns.histplot(cyber_df['security_incidents'], bins=30, kde=True)\nplt.title(\"Histogram of Security Incidents (Original)\")\nplt.xlabel(\"Number of Security Incidents\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n#Explore relationships via scatter plots\n\n#incidents vs. vuln_count\nplt.figure(figsize=(8, 5))\nsns.scatterplot(x='vuln_count', y='security_incidents', data=cyber_df)\nplt.title(\"Security Incidents vs. Vulnerability Count\")\nplt.xlabel(\"Vulnerability Count\")\nplt.ylabel(\"Security Incidents\")\nplt.show()\n\n#incidents vs. mean_time_to_patch\nplt.figure(figsize=(8, 5))\nsns.scatterplot(x='mean_time_to_patch', y='security_incidents', data=cyber_df)\nplt.title(\"Security Incidents vs. Mean Time to Patch\")\nplt.xlabel(\"Mean Time to Patch (days)\")\nplt.ylabel(\"Security Incidents\")\nplt.show()\n\n#Skewness and Log Transformation\n\n#original skewness\norig_skew = skew(cyber_df['security_incidents'].dropna())\nprint(f\"Skewness of security_incidents (original): {orig_skew:.2f}\")\n\n#log transform\ncyber_df['log_security_incidents'] = np.log1p(cyber_df['security_incidents'])\n\n#skewness after transformation\nlog_skew = skew(cyber_df['log_security_incidents'].dropna())\nprint(f\"Skewness after log transformation: {log_skew:.2f}\")\n\n#plot log-transformed histogram\nplt.figure(figsize=(8, 5))\nsns.histplot(cyber_df['log_security_incidents'], bins=30, kde=True)\nplt.title(\"Histogram of Log-Transformed Security Incidents\")\nplt.xlabel(\"log(1 + Security Incidents)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92f8ecca-5b50-4024-9c47-77100d16e772",
   "metadata": {
    "language": "python",
    "name": "Transform"
   },
   "outputs": [],
   "source": "#check skewness of all continuous variables first\nprint(\"Skewness Analysis of Original Variables:\")\nprint(\"=\" * 70)\n\noriginal_continuous = [\n    'org_size', 'it_budget_per_emp', 'mfa_coverage', 'endpoint_coverage',\n    'vuln_count', 'mean_time_to_patch', 'phishing_sim_click_rate',\n    'training_completion_rate', 'login_failures_per_user',\n    'cloud_misconfig_count', 'security_incidents'\n]\n\nfor var in original_continuous:\n    sk = skew(cyber_df[var].dropna())\n    interpretation = \"Highly skewed\" if abs(sk) > 1 else \"Moderately skewed\" if abs(sk) > 0.5 else \"Roughly symmetric\"\n    print(f\"{var:30s}: {sk:6.2f} - {interpretation}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Applying Log Transformations to Highly Skewed Variables:\")\nprint(\"=\" * 70)\n\n#log transform highly skewed variables\ncyber_df['log_org_size'] = np.log1p(cyber_df['org_size'])\ncyber_df['log_vuln_count'] = np.log1p(cyber_df['vuln_count'])\ncyber_df['log_security_incidents'] = np.log1p(cyber_df['security_incidents'])\ncyber_df['log_mean_time_to_patch'] = np.log1p(cyber_df['mean_time_to_patch'])\ncyber_df['log_login_failures'] = np.log1p(cyber_df['login_failures_per_user'])\ncyber_df['log_cloud_misconfig'] = np.log1p(cyber_df['cloud_misconfig_count'])\n\n#verify transformations reduced skewness\nprint(\"\\nSkewness After Transformation:\")\ntransformed_vars = {\n    'log_org_size': cyber_df['log_org_size'],\n    'log_vuln_count': cyber_df['log_vuln_count'],\n    'log_security_incidents': cyber_df['log_security_incidents'],\n    'log_mean_time_to_patch': cyber_df['log_mean_time_to_patch'],\n    'log_login_failures': cyber_df['log_login_failures'],\n    'log_cloud_misconfig': cyber_df['log_cloud_misconfig']\n}\n\nfor name, series in transformed_vars.items():\n    sk = skew(series.dropna())\n    print(f\"{name:30s}: {sk:6.2f}\")\n\ncyber_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ec8db80-200c-436b-94d5-92c362f653b2",
   "metadata": {
    "language": "python",
    "name": "PCASetupAndStandardize"
   },
   "outputs": [],
   "source": "#select continuous variables for PCA - using TRANSFORMED versions where applicable\ncontinuous_vars = [\n    'log_org_size',                    # transformed from org_size\n    'it_budget_per_emp',               # not skewed, use original\n    'mfa_coverage',                    # not skewed, use original\n    'endpoint_coverage',               # not skewed, use original\n    'log_vuln_count',                  # transformed from vuln_count\n    'log_mean_time_to_patch',          # transformed from mean_time_to_patch\n    'phishing_sim_click_rate',         # not skewed, use original\n    'training_completion_rate',        # not skewed, use original\n    'log_login_failures',              # transformed from login_failures_per_user\n    'log_cloud_misconfig',             # transformed from cloud_misconfig_count\n    'log_security_incidents'           # transformed from security_incidents\n]\n\nprint(\"Variables selected for PCA (using transformed versions):\")\nprint(\"=\" * 70)\nfor i, var in enumerate(continuous_vars, 1):\n    print(f\"{i:2d}. {var}\")\n\n#create a clean dataset with no missing values\npca_data = cyber_df[continuous_vars].dropna()\n\nprint(f\"\\nPCA Dataset shape: {pca_data.shape}\")\nprint(f\"Number of observations: {pca_data.shape[0]}\")\nprint(f\"Number of variables: {pca_data.shape[1]}\")\n\n#standardize the data (mean=0, std=1)\nscaler = StandardScaler()\ndata_standardized = scaler.fit_transform(pca_data)\n\nprint(\"\\n✓ Data has been standardized for PCA\")\nprint(f\"✓ Standardized data shape: {data_standardized.shape}\")\nprint(f\"✓ Mean of standardized data: {data_standardized.mean():.6f} (should be ~0)\")\nprint(f\"✓ Std of standardized data: {data_standardized.std():.6f} (should be ~1)\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f82a82a6-d183-4f67-ae50-11bd50498e8d",
   "metadata": {
    "language": "python",
    "name": "PCA"
   },
   "outputs": [],
   "source": "#Fit PCA and analyze explained variance\n\n#fit PCA with all components\npca = PCA()\npca_components = pca.fit_transform(data_standardized)\n\n#get explained variance\nexplained_variance = pca.explained_variance_ratio_\ncumulative_variance = np.cumsum(explained_variance)\n\n#display variance explained by each component\nvariance_df = pd.DataFrame({\n    'PC': [f'PC{i+1}' for i in range(len(explained_variance))],\n    'Explained Variance': explained_variance,\n    'Cumulative Variance': cumulative_variance\n})\n\nprint(\"Explained Variance by Principal Component:\\n\")\nprint(variance_df)\n\n#visualize explained variance\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n#scree plot\naxes[0].bar(range(1, len(explained_variance) + 1), explained_variance)\naxes[0].set_xlabel('Principal Component')\naxes[0].set_ylabel('Explained Variance Ratio')\naxes[0].set_title('Scree Plot: Variance Explained by Each PC')\naxes[0].set_xticks(range(1, len(explained_variance) + 1))\n\n#cumulative variance plot\naxes[1].plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\naxes[1].axhline(y=0.8, color='r', linestyle='--', label='80% threshold')\naxes[1].axhline(y=0.9, color='g', linestyle='--', label='90% threshold')\naxes[1].set_xlabel('Number of Principal Components')\naxes[1].set_ylabel('Cumulative Explained Variance')\naxes[1].set_title('Cumulative Variance Explained')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n#determine number of components needed for 80% and 90% variance\nn_components_80 = np.argmax(cumulative_variance >= 0.80) + 1\nn_components_90 = np.argmax(cumulative_variance >= 0.90) + 1\n\nprint(f\"\\nComponents needed for 80% variance: {n_components_80}\")\nprint(f\"Components needed for 90% variance: {n_components_90}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "412e5ea1-a008-4e02-beca-1f03165cb415",
   "metadata": {
    "language": "python",
    "name": "Analyze"
   },
   "outputs": [],
   "source": "#Analyze component loadings\n\n#get the loadings (correlation between original variables and PCs)\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n\n#create a dataframe for easier interpretation\n#focus on the first few most important components\nn_components_to_show = min(5, len(explained_variance))\n\nloadings_df = pd.DataFrame(\n    loadings[:, :n_components_to_show],\n    columns=[f'PC{i+1}' for i in range(n_components_to_show)],\n    index=continuous_vars\n)\n\nprint(\"Component Loadings (correlations with original variables):\\n\")\nprint(loadings_df.round(3))\n\n#visualize loadings as a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(loadings_df, annot=True, cmap='RdBu_r', center=0, \n            fmt='.2f', cbar_kws={'label': 'Loading'})\nplt.title('PCA Loadings Heatmap: Variable Contributions to Principal Components')\nplt.xlabel('Principal Component')\nplt.ylabel('Original Variables')\nplt.tight_layout()\nplt.show()\n\n#show strongest contributors to each PC\nprint(\"\\nStrongest contributors to each principal component:\")\nfor i in range(n_components_to_show):\n    pc_name = f'PC{i+1}'\n    loadings_sorted = loadings_df[pc_name].abs().sort_values(ascending=False)\n    print(f\"\\n{pc_name} (explains {explained_variance[i]:.1%} of variance):\")\n    for var, loading in loadings_sorted.head(3).items():\n        actual_loading = loadings_df.loc[var, pc_name]\n        print(f\"  {var}: {actual_loading:.3f}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbd277c5-c3b8-41b1-966d-5697e2246a24",
   "metadata": {
    "language": "python",
    "name": "ProjectData"
   },
   "outputs": [],
   "source": "#project data onto principal components\n\n#define optimal_n before using it\noptimal_n = n_components_90\n\n#debug: Check what PCA is\nprint(f\"Type of PCA: {type(PCA)}\")\nprint(f\"Optimal n_components: {optimal_n}\")\n\n#refit PCA with optimal number of components (let's use components for 90% variance)\npca_optimal = PCAModel(n_components=optimal_n)\npca_transformed = pca_optimal.fit_transform(data_standardized)\n\n#create dataframe with projected data\npca_df = pd.DataFrame(\n    pca_transformed,\n    columns=[f'PC{i+1}' for i in range(optimal_n)],\n    index=pca_data.index\n)\n\n#add back some categorical variables for context\npca_df['department'] = cyber_df.loc[pca_data.index, 'department'].values\npca_df['quarter'] = cyber_df.loc[pca_data.index, 'quarter'].values\npca_df['security_incidents'] = cyber_df.loc[pca_data.index, 'security_incidents'].values\n\nprint(f\"Projected data shape: {pca_df.shape}\")\nprint(\"\\nFirst few rows of projected data:\")\nprint(pca_df.head())\n\n#visualize first two principal components\nplt.figure(figsize=(12, 5))\n\n#colored by department\nplt.subplot(1, 2, 1)\nfor dept in pca_df['department'].unique():\n    mask = pca_df['department'] == dept\n    plt.scatter(pca_df.loc[mask, 'PC1'], pca_df.loc[mask, 'PC2'], \n                label=dept, alpha=0.6)\nplt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\nplt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\nplt.title('PCA Projection by Department')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n#colored by security incidents (continuous)\nplt.subplot(1, 2, 2)\nscatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], \n                     c=pca_df['security_incidents'], \n                     cmap='YlOrRd', alpha=0.6)\nplt.colorbar(scatter, label='Security Incidents')\nplt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\nplt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\nplt.title('PCA Projection by Security Incidents')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "992ca3d1-b11b-4793-bbf7-ce86e5fc6306",
   "metadata": {
    "name": "InterpretationCommentary",
    "collapsed": false
   },
   "source": "I built some interpretation code to generate recommendations and provide insights based on the PCA (and data) as analyzed."
  },
  {
   "cell_type": "code",
   "id": "6f5917a8-d886-4a4d-86d7-a367b3332ac2",
   "metadata": {
    "language": "python",
    "name": "Interpretation"
   },
   "outputs": [],
   "source": "#interpretation and insights\n\nprint(\"=\" * 80)\nprint(\"PCA INTERPRETATION AND INSIGHTS\")\nprint(\"=\" * 80)\n\nprint(\"\\n1. DIMENSIONALITY REDUCTION:\")\nprint(f\"   - Original dimensions: {len(continuous_vars)} variables\")\nprint(f\"   - Reduced to {optimal_n} principal components\")\nprint(f\"   - Retained variance: {cumulative_variance[optimal_n-1]:.1%}\")\n\nprint(\"\\n2. PRINCIPAL COMPONENT MEANINGS:\")\n\n#interpret based on loadings\nfor i in range(min(3, optimal_n)):  # Interpret first 3 PCs\n    pc_name = f'PC{i+1}'\n    print(f\"\\n   {pc_name} ({explained_variance[i]:.1%} of variance):\")\n    \n    #get top positive and negative loadings\n    pc_loadings = loadings_df.iloc[:, i].sort_values()\n    \n    print(f\"   Strong negative associations: {pc_loadings.head(2).to_dict()}\")\n    print(f\"   Strong positive associations: {pc_loadings.tail(2).to_dict()}\")\n    \n    #provide intuitive interpretation\n    if i == 0:\n        print(\"   Interpretation: This likely represents 'organizational scale and cybersecurity posture'\")\n    elif i == 1:\n        print(\"   Interpretation: This likely represents 'security hygiene and response effectiveness'\")\n    elif i == 2:\n        print(\"   Interpretation: This likely represents 'human factor vulnerabilities'\")\n\nprint(\"\\n3. WHAT I RECOMMEND WE DO:\")\nprint(\"   - Create a cybersecurity maturity score based on PC1 (most important - for creating a baseline against tracking future progress\")\nprint(\"   - Use these Principal Components for clustering to identify similar security profiles\")\nprint(\"   - Build predictive models with reduced features (less overfitting)\")\nprint(\"   - Identify departments that are outliers in Principal Component space\")\nprint(\"   - Track cybersecurity posture changes over time using Principal Component coordinates\")\n\n#calculate correlation between PC1 and security incidents\npc1_incident_corr = np.corrcoef(pca_df['PC1'], pca_df['security_incidents'])[0, 1]\n\nprint(\"\\n4. KEY INSIGHTS:\")\nprint(f\"   - PC1 correlation with security incidents: {pc1_incident_corr:.3f}\")\nprint(f\"   - Most variance comes from organizational and cybersecurity control differences\")\nprint(f\"   - {optimal_n} dimensions capture the essential patterns in our cybersecurity posture\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0929dc34-dcad-414a-b85e-938dc3da731d",
   "metadata": {
    "name": "AcionableInsightsSetup",
    "collapsed": false
   },
   "source": "Next, I added some code to build textual recommendations.  I learned how to add these to a file that includes text I can then add into a markdown cell (which I did). Probably overkill, but as the model improved I kept coming up with more, potential conclusions for a more comprehensive recommendation list.  I made a couple of passes at how to build the recommendations.  They are next as ActionableInsightsCode, followed by ActionableInsightsCommentary (markdown).  There are two versions as I wanted to try a couple of different approaches."
  },
  {
   "cell_type": "code",
   "id": "9b519b4f-026d-43b6-bb82-535398b71339",
   "metadata": {
    "language": "python",
    "name": "ActionableInsightsCode1of2"
   },
   "outputs": [],
   "source": "# COMPREHENSIVE ANALYSIS WITH AUTO-GENERATED MARKDOWN CONCLUSION\n\nprint(\"=\" * 80)\nprint(\"DETAILED ANALYSIS FOR ACTIONABLE RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# PART 1: IDENTIFY KEY DRIVERS OF SECURITY INCIDENTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 1: WHAT DRIVES SECURITY INCIDENTS?\")\nprint(\"=\" * 80)\n\n#calculate correlation of each PC with security incidents\npc_incident_correlations = {}\nfor i in range(optimal_n):\n    pc_col = f'PC{i+1}'\n    corr = np.corrcoef(pca_df[pc_col], pca_df['security_incidents'])[0, 1]\n    pc_incident_correlations[pc_col] = corr\n    print(f\"\\n{pc_col} correlation with security incidents: {corr:.3f}\")\n    print(f\"  Variance explained: {explained_variance[i]:.1%}\")\n\n#find most important PC (highest absolute correlation with incidents)\nmost_correlated_pc_name = max(pc_incident_correlations, key=lambda k: abs(pc_incident_correlations[k]))\nmost_correlated_pc_idx = int(most_correlated_pc_name.replace('PC', '')) - 1\nmost_correlated_pc_corr = pc_incident_correlations[most_correlated_pc_name]\n\nprint(f\"\\n>>> MOST IMPORTANT: {most_correlated_pc_name}\")\nprint(f\"    Correlation with incidents: {most_correlated_pc_corr:.3f}\")\nprint(f\"    Variance explained: {explained_variance[most_correlated_pc_idx]:.1%}\")\n\n# ============================================================================\n# PART 2: IDENTIFY TOP VARIABLES TO ADDRESS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 2: TOP VARIABLES THAT NEED ATTENTION\")\nprint(\"=\" * 80)\n\n#calculate leverage scores (variance explained * correlation with incidents)\npc_incident_corrs_list = []\nfor i in range(optimal_n):\n    pc_col = f'PC{i+1}'\n    corr = abs(np.corrcoef(pca_df[pc_col], pca_df['security_incidents'])[0, 1])\n    pc_incident_corrs_list.append(corr)\n\n#weight by both variance explained and correlation with incidents\nleverage_scores = explained_variance[:optimal_n] * np.array(pc_incident_corrs_list)\nmost_important_pc_idx = np.argmax(leverage_scores)\nmost_important_pc_name = f'PC{most_important_pc_idx + 1}'\n\nprint(f\"\\nMost important PC for reducing incidents: {most_important_pc_name}\")\nprint(f\"  - Explains {explained_variance[most_important_pc_idx]:.1%} of variance\")\nprint(f\"  - Correlation with incidents: {pc_incident_corrs_list[most_important_pc_idx]:.3f}\")\nprint(f\"  - Leverage score: {leverage_scores[most_important_pc_idx]:.3f}\")\n\n#get top 5 variables by absolute loading on most important PC\ntop_5_vars = loadings_df[most_important_pc_name].abs().sort_values(ascending=False).head(5)\n\nprint(f\"\\nTop 5 variables loading on {most_important_pc_name}:\")\ntop_vars_list = []\n\nfor rank, (var, abs_loading) in enumerate(top_5_vars.items(), 1):\n    actual_loading = loadings_df.loc[var, most_important_pc_name]\n    \n    #determine if higher values lead to more or fewer incidents\n    #positive loading + positive PC-incident correlation = higher values cause more incidents\n    #negative loading + positive PC-incident correlation = lower values cause more incidents\n    pc_incident_corr = pc_incident_correlations[most_important_pc_name]\n    \n    if (actual_loading > 0 and pc_incident_corr > 0) or (actual_loading < 0 and pc_incident_corr < 0):\n        direction = \"Higher\"\n        effect = \"MORE incidents\"\n        action = \"REDUCE\"\n    else:\n        direction = \"Lower\"  \n        effect = \"FEWER incidents\"\n        action = \"INCREASE\"\n    \n    print(f\"\\n{rank}. {var}\")\n    print(f\"   Loading: {actual_loading:.3f}\")\n    print(f\"   Effect: {direction} values → {effect}\")\n    print(f\"   → ACTION: {action} this metric\")\n    \n    top_vars_list.append({\n        'rank': rank,\n        'variable': var,\n        'loading': actual_loading,\n        'abs_loading': abs_loading,\n        'direction': direction,\n        'effect': effect,\n        'action': action\n    })\n\n# ============================================================================\n# PART 3: SPECIFIC ACTIONABLE RECOMMENDATIONS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 3: SPECIFIC, ACTIONABLE RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\n#detailed recommendations for each variable\nrecommendations_detailed = {\n    'log_mean_time_to_patch': {\n        'problem': 'Slow patching increases vulnerability window',\n        'quick_win': 'Prioritize critical patches, automate patch deployment for 30% of systems',\n        'medium': 'Hire 1-2 dedicated patch management specialists ($120k-150k/year)',\n        'long': 'Implement enterprise patch management system ($50k tool + 2 FTE)',\n        'metric': 'Reduce mean time to patch from current to <7 days for critical patches'\n    },\n    'log_vuln_count': {\n        'problem': 'High vulnerability counts indicate scanning or remediation gaps',\n        'quick_win': 'Increase vulnerability scan frequency to weekly',\n        'medium': 'Create vulnerability management SLA: Critical (7 days), High (30 days)',\n        'long': 'Hire security engineer focused on vulnerability management ($130k-160k)',\n        'metric': 'Reduce total vulnerability count by 40% in 12 months'\n    },\n    'training_completion_rate': {\n        'problem': 'Incomplete training leaves users vulnerable to social engineering',\n        'quick_win': 'Make security training mandatory with executive sponsorship',\n        'medium': 'Implement quarterly micro-learning modules (10 min each)',\n        'long': 'Gamify training with rewards, track completion in performance reviews',\n        'metric': 'Achieve 95%+ completion rate within 6 months'\n    },\n    'phishing_sim_click_rate': {\n        'problem': 'High click rates indicate users are vulnerable to phishing',\n        'quick_win': 'Run monthly phishing simulations with immediate educational pop-ups',\n        'medium': 'Implement targeted training for repeat clickers',\n        'long': 'Deploy email security solution with URL rewriting and sandboxing ($15-20/user/year)',\n        'metric': 'Reduce click rate from current to <5% organization-wide'\n    },\n    'mfa_coverage': {\n        'problem': 'Accounts without MFA are vulnerable to credential compromise',\n        'quick_win': 'Mandate MFA for all admin and privileged accounts (immediate)',\n        'medium': 'Require MFA for all users accessing corporate resources (90 days)',\n        'long': 'Implement passwordless authentication (FIDO2) for 50% of users',\n        'metric': 'Achieve 100% MFA coverage for all users within 3 months'\n    },\n    'endpoint_coverage': {\n        'problem': 'Unprotected endpoints are entry points for malware',\n        'quick_win': 'Audit all endpoints, identify gaps, create deployment plan',\n        'medium': 'Deploy EDR to remaining endpoints ($40-60/endpoint/year)',\n        'long': 'Implement zero-trust architecture with continuous endpoint verification',\n        'metric': 'Achieve 100% endpoint coverage within 6 months'\n    },\n    'log_login_failures': {\n        'problem': 'High login failures may indicate brute force attacks or poor UX',\n        'quick_win': 'Implement account lockout after 5 failed attempts',\n        'medium': 'Deploy password manager to all users ($5-10/user/year)',\n        'long': 'Implement SSO with adaptive authentication',\n        'metric': 'Reduce login failures by 60% through better UX and security'\n    },\n    'log_cloud_misconfig': {\n        'problem': 'Cloud misconfigurations expose data and services',\n        'quick_win': 'Run immediate cloud security audit using free tools',\n        'medium': 'Implement Cloud Security Posture Management (CSPM) tool ($20k-50k/year)',\n        'long': 'Hire cloud security engineer or consultant ($140k-180k or $200/hr)',\n        'metric': 'Reduce misconfigurations by 80%, maintain <5 open issues'\n    },\n    'it_budget_per_emp': {\n        'problem': 'Insufficient budget limits security program effectiveness',\n        'quick_win': 'Document current budget gaps with business risk analysis',\n        'medium': 'Request 20-30% budget increase with ROI justification',\n        'long': 'Benchmark against industry standards, align budget to risk appetite',\n        'metric': 'Increase security budget to industry median per employee'\n    },\n    'log_org_size': {\n        'problem': 'Larger organizations face scale challenges',\n        'quick_win': 'Implement automation for repetitive security tasks',\n        'medium': 'Scale security team proportionally (1 security FTE per 100 employees)',\n        'long': 'Build security centers of excellence for enterprise-wide consistency',\n        'metric': 'Maintain consistent security posture regardless of org size'\n    },\n    'log_security_incidents': {\n        'problem': 'Lack of visibility into incident trends',\n        'quick_win': 'Implement standardized incident reporting and tracking',\n        'medium': 'Deploy SIEM for centralized security monitoring ($30k-100k/year)',\n        'long': 'Build SOC capability with 24/7 monitoring',\n        'metric': 'Reduce mean time to detect (MTTD) to <1 hour'\n    }\n}\n\nprint(\"\\nDETAILED RECOMMENDATIONS FOR TOP 5 DRIVERS:\\n\")\nfor item in top_vars_list:\n    var = item['variable']\n    rank = item['rank']\n    loading = item['loading']\n    action = item['action']\n    \n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        print(f\"\\n{'='*70}\")\n        print(f\"#{rank}: {var} (loading: {loading:.3f})\")\n        print(f\"ACTION NEEDED: {action} this metric\")\n        print(f\"{'='*70}\")\n        print(f\"PROBLEM: {rec['problem']}\")\n        print(f\"\\n→ QUICK WIN (0-3 months, low cost):\")\n        print(f\"  {rec['quick_win']}\")\n        print(f\"\\n→ MEDIUM-TERM (3-6 months, moderate investment):\")\n        print(f\"  {rec['medium']}\")\n        print(f\"\\n→ LONG-TERM (6-12 months, significant investment):\")\n        print(f\"  {rec['long']}\")\n        print(f\"\\n→ SUCCESS METRIC:\")\n        print(f\"  {rec['metric']}\")\n\n# ============================================================================\n# PART 4: DEPARTMENT-SPECIFIC RECOMMENDATIONS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 4: DEPARTMENT-SPECIFIC RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\ndept_pc_means = pca_df.groupby('department')[[f'PC{i+1}' for i in range(min(3, optimal_n))]].mean()\ndept_incidents = pca_df.groupby('department')['security_incidents'].mean()\n\nprint(\"\\nDepartment Profiles:\")\nprint(\"-\" * 70)\ndept_analysis = pd.concat([dept_pc_means, dept_incidents], axis=1)\nprint(dept_analysis.round(2))\n\n#identify best and worst performers\nbest_dept = dept_incidents.idxmin()\nworst_dept = dept_incidents.idxmax()\n\nprint(f\"\\n>>> BEST PERFORMER: {best_dept}\")\nprint(f\"    Average incidents: {dept_incidents[best_dept]:.1f}\")\nprint(f\"    PC1 score: {dept_pc_means.loc[best_dept, 'PC1']:.2f}\")\n\nprint(f\"\\n>>> NEEDS MOST ATTENTION: {worst_dept}\")\nprint(f\"    Average incidents: {dept_incidents[worst_dept]:.1f}\")\nprint(f\"    PC1 score: {dept_pc_means.loc[worst_dept, 'PC1']:.2f}\")\n\nprint(f\"\\nRECOMMENDATION: Have {best_dept} share best practices with {worst_dept}\")\n\n#specific recommendations by department\nprint(\"\\n\" + \"-\" * 70)\nprint(\"DEPARTMENT-SPECIFIC ACTION PLANS:\")\nprint(\"-\" * 70)\n\nfor dept in dept_pc_means.index:\n    print(f\"\\n{dept.upper()}:\")\n    pc1_score = dept_pc_means.loc[dept, 'PC1']\n    pc2_score = dept_pc_means.loc[dept, 'PC2'] if 'PC2' in dept_pc_means.columns else 0\n    avg_incidents = dept_incidents[dept]\n    \n    print(f\"  Current incidents/quarter: {avg_incidents:.1f}\")\n    print(f\"  PC1 score: {pc1_score:.2f} | PC2 score: {pc2_score:.2f}\")\n    \n    #interpret PC1\n    if pc1_score > 0.5:\n        print(f\"  • Large/complex organization - prioritize automation and additional staff\")\n    elif pc1_score < -0.5:\n        print(f\"  • Smaller organization - focus on foundational controls first\")\n    else:\n        print(f\"  • Medium-sized organization - balanced approach needed\")\n    \n    #interpret PC2 if available\n    if 'PC2' in dept_pc_means.columns:\n        if pc2_score < -0.5:\n            print(f\"  • WEAK controls - PRIORITY: improve coverage metrics (MFA, endpoints)\")\n        elif pc2_score > 0.5:\n            print(f\"  • STRONG controls - maintain and focus on advanced threats\")\n    \n    #compare to org average\n    if avg_incidents > dept_incidents.mean():\n        print(f\"  ⚠️  ABOVE AVERAGE INCIDENTS - needs immediate attention\")\n    else:\n        print(f\"  ✓  Below average incidents - share practices with other teams\")\n\n# ============================================================================\n# PART 5: ROI AND IMPACT ESTIMATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 5: ESTIMATED IMPACT AND ROI\")\nprint(\"=\" * 80)\n\ncurrent_mean_incidents = pca_df['security_incidents'].mean()\ncurrent_total_incidents = pca_df['security_incidents'].sum()\nn_dept_quarters = len(pca_df)\n\nprint(f\"\\nCURRENT STATE:\")\nprint(f\"  Average incidents per dept/quarter: {current_mean_incidents:.1f}\")\nprint(f\"  Total incidents in dataset: {current_total_incidents:.0f}\")\nprint(f\"  Number of observations: {n_dept_quarters}\")\n\n#estimate impact based on correlation\ncorrelation_strength = abs(most_correlated_pc_corr)\nestimated_reduction_pct = min(correlation_strength * 100, 60)  # Cap at 60%\n\nprint(f\"\\nESTIMATED IMPACT:\")\nprint(f\"  {most_correlated_pc_name} correlation with incidents: {most_correlated_pc_corr:.3f}\")\nprint(f\"  By improving top 3-5 factors by 1 standard deviation:\")\nprint(f\"    • Expected incident reduction: ~{estimated_reduction_pct:.0f}%\")\nprint(f\"    • From {current_mean_incidents:.1f} to ~{current_mean_incidents * (1 - estimated_reduction_pct/100):.1f} incidents/quarter\")\nprint(f\"    • Annual reduction: ~{current_mean_incidents * 4 * estimated_reduction_pct/100:.0f} fewer incidents/year\")\n\n#cost-benefit\nprint(f\"\\nESTIMATED COSTS:\")\nprint(f\"  Quick wins: $0-10k (reallocate existing resources)\")\nprint(f\"  Medium-term: $100k-300k (tools + 1-2 FTE)\")\nprint(f\"  Long-term: $300k-600k/year (comprehensive program)\")\n\nprint(f\"\\nESTIMATED BENEFITS (assuming $50k cost per incident):\")\nincidents_prevented = current_mean_incidents * 4 * estimated_reduction_pct / 100\ncost_per_incident = 50000  # Adjust this for your organization\nannual_savings = incidents_prevented * cost_per_incident\n\nprint(f\"  Incidents prevented per year: ~{incidents_prevented:.0f}\")\nprint(f\"  Annual cost savings: ${annual_savings:,.0f}\")\nprint(f\"  ROI: {(annual_savings / 300000 - 1) * 100:.0f}% (against medium-term investment)\")\n\n# ============================================================================\n# PART 6: AUTO-GENERATE MARKDOWN CONCLUSION\n# ============================================================================\n\n#print(\"\\n\" + \"=\" * 80)\n#print(\"AUTO-GENERATED MARKDOWN CONCLUSION (COPY-PASTE BELOW)\")\n#print(\"=\" * 80)\n\n#interpret what PC1 represents based on loadings\npc1_top_var = loadings_df.iloc[:, 0].abs().idxmax()\npc1_interpretation = \"organizational scale and security complexity\"\nif 'training' in pc1_top_var or 'phishing' in pc1_top_var:\n    pc1_interpretation = \"human factor vulnerabilities and training effectiveness\"\nelif 'coverage' in pc1_top_var or 'mfa' in pc1_top_var:\n    pc1_interpretation = \"security control coverage and maturity\"\n\nmarkdown_output = f\"\"\"\n# Conclusion: Actionable Insights from PCA\n\n## What We Learned\n\nThis PCA analysis revealed that **{optimal_n} principal components** capture **{cumulative_variance[optimal_n-1]:.1%}** of the variance in our cybersecurity data, with **PC1 primarily representing {pc1_interpretation}**, explaining **{explained_variance[0]:.1%}** of the variance.\n\nThe analysis successfully reduced our monitoring from 11 separate metrics to {optimal_n} composite dimensions that capture the essential patterns in our security posture.\n\n## Key Finding: What Drives Security Incidents\n\n**{most_correlated_pc_name} shows the strongest relationship with security incidents** (correlation: **{most_correlated_pc_corr:.3f}**), explaining **{explained_variance[most_correlated_pc_idx]:.1%}** of variance. This tells us that focusing on the variables that load heavily on {most_correlated_pc_name} will have the greatest impact on reducing incidents.\n\n## Specific Recommendations (Prioritized by Impact)\n\nBased on the PCA loadings and their correlation with security incidents, we identified the following **prioritized actions**:\n\n### 1. Immediate Actions (Highest ROI - Implement in 0-3 months)\n\"\"\"\n\nfor item in top_vars_list[:3]:\n    var = item['variable']\n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        markdown_output += f\"\"\"\n**{item['rank']}. {var}** (loading: {item['loading']:.3f}, ACTION: {item['action']})\n- **Problem**: {rec['problem']}\n- **Action**: {rec['quick_win']}\n- **Target**: {rec['metric']}\n\"\"\"\n\nmarkdown_output += f\"\"\"\n### 2. Medium-Term Investments (3-6 months, ~$100k-300k)\n\"\"\"\n\nfor item in top_vars_list[:3]:\n    var = item['variable']\n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        markdown_output += f\"\"\"\n**{var}**: {rec['medium']}\n\"\"\"\n\nmarkdown_output += f\"\"\"\n### 3. Long-Term Strategic Initiatives (6-12 months, ~$300k-600k/year)\n\"\"\"\n\nfor item in top_vars_list[:3]:\n    var = item['variable']\n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        markdown_output += f\"\"\"\n**{var}**: {rec['long']}\n\"\"\"\n\nmarkdown_output += f\"\"\"\n## Why These Matter\n\n- **{most_correlated_pc_name}** explains {explained_variance[most_correlated_pc_idx]:.1%} of variance and correlates **{most_correlated_pc_corr:.3f}** with security incidents\n- The top {len(top_vars_list)} variables loading on {most_correlated_pc_name} are directly actionable with clear interventions\n- Improving these by 1 standard deviation could reduce incidents by approximately **{estimated_reduction_pct:.0f}%**\n\n## Department-Specific Focus\n\n**Best Performer**: **{best_dept}** (average {dept_incidents[best_dept]:.1f} incidents/quarter)\n- Share their practices with other departments\n- Document their success factors for replication\n\n**Needs Most Attention**: **{worst_dept}** (average {dept_incidents[worst_dept]:.1f} incidents/quarter)\n- Immediate intervention required\n- Assign dedicated security resource for 90 days\n- Implement quick wins from list above\n\n### All Departments:\n\"\"\"\n\nfor dept in dept_pc_means.index:\n    avg_incidents = dept_incidents[dept]\n    status = \"⚠️ Above average\" if avg_incidents > dept_incidents.mean() else \"✓ Below average\"\n    \n    markdown_output += f\"\"\"\n**{dept}**: {avg_incidents:.1f} incidents/quarter ({status})\n\"\"\"\n\nmarkdown_output += f\"\"\"\n## Resource Requirements\n\nTo implement these recommendations:\n\n| Timeline | Investment | Key Activities |\n|----------|-----------|----------------|\n| **Quick wins (0-3 months)** | $0-10k | Mandatory training, MFA for admins, phishing sims |\n| **Medium-term (3-6 months)** | $100k-300k | 1-2 FTE hires, EDR deployment, CSPM tool |\n| **Long-term (6-12 months)** | $300k-600k/year | Additional staff, enterprise tools, automation |\n\n## Expected Outcomes\n\n### Quantitative Targets (12-month goals):\n- **Reduce security incidents by {estimated_reduction_pct:.0f}%** (from {current_mean_incidents:.1f} to ~{current_mean_incidents * (1 - estimated_reduction_pct/100):.1f} per dept/quarter)\n- Achieve **100% MFA coverage** across all users\n- Reduce **mean time to patch to <7 days** for critical vulnerabilities\n- Increase **training completion to 95%+** organization-wide\n- Reduce **phishing click rate to <5%**\n\n### Return on Investment:\n- **Annual incidents prevented**: ~{incidents_prevented:.0f}\n- **Estimated annual savings**: ${annual_savings:,.0f} (at ${cost_per_incident:,} per incident)\n- **ROI**: ~{(annual_savings / 300000 - 1) * 100:.0f}% on medium-term investment\n\n## Measuring Success\n\nTrack these PC scores quarterly to monitor improvement:\n\n- **Target**: Move all departments' {most_correlated_pc_name} scores closer to {best_dept}'s profile\n- **Dashboard**: Create quarterly PC score tracking with incident trends\n- **Review**: Executive review of security posture using PC metrics (simpler than 11 individual metrics)\n\n## Why PCA Was Valuable\n\nRather than tracking 11 separate metrics independently, PCA showed us that:\n\n1. **Most variation comes from just {optimal_n} underlying factors** - we can focus our attention\n2. **We can prioritize resources** on variables that load heavily on incident-correlated PCs ({most_correlated_pc_name})\n3. **We have a quantitative basis** for budget requests: \"Investing $300k in these {len(top_vars_list[:3])} areas will reduce incidents by {estimated_reduction_pct:.0f}%\"\n4. **Departments can be compared** fairly using PC scores rather than raw metrics that don't account for size/complexity\n\nThis transforms cybersecurity from reactive firefighting to **proactive, data-driven risk management** with clear priorities and measurable outcomes.\n\n## Next Steps\n\n1. **Week 1**: Present findings to leadership, secure budget approval for quick wins\n2. **Month 1**: Implement all quick wins, begin hiring for medium-term roles\n3. **Month 3**: Deploy tools (EDR, CSPM), complete first round of enhanced training\n4. **Month 6**: Review PC scores, measure incident reduction, adjust strategy\n5. **Month 12**: Full program assessment, demonstrate ROI, plan next phase\n\n---\n\n*Analysis based on {n_dept_quarters} department-quarter observations across {len(pca_df['department'].unique())} departments over {len(pca_df['quarter'].unique())} quarters.*\n\"\"\"\n\n#print(markdown_output)\n#commented out as I copied to a separate markdown cell after generating\n\n#save to file for easy copying\ntry:\n    with open('PCA_Conclusion_AutoGenerated.md', 'w') as f:\n        f.write(markdown_output)\n    print(\"\\n\" + \"=\" * 80)\n    print(\"✓ Markdown conclusion saved to: PCA_Conclusion_AutoGenerated.md and pasted to markdown cell just below:\")\n    print(\"=\" * 80)\nexcept:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Note: Could not save to file, but markdown is printed above\")\n    print(\"=\" * 80)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51bb5abb-c5b3-4eb1-92b1-60655e566876",
   "metadata": {
    "name": "ActionableInsightsCommentary1of2",
    "collapsed": false
   },
   "source": "# Conclusion: Actionable Insights from PCA  \n## What We Learned  \nThis PCA analysis revealed that **8 principal components** capture **91.7%** of the variance in our cybersecurity data, with **PC1 primarily representing organizational scale and security complexity**, explaining **20.5%** of the variance.  \nThe analysis successfully reduced our monitoring from 11 separate metrics to 8 composite dimensions that capture the essential patterns in our security posture.  \n## Key Finding: What Drives Security Incidents  \n**PC1 shows the strongest relationship with security incidents** (correlation: **0.688**), explaining **20.5%** of variance. This tells us that focusing on the variables that load heavily on PC1 will have the greatest impact on reducing incidents.  \n## Specific Recommendations (Prioritized by Impact)  \nBased on the PCA loadings and their correlation with security incidents, we identified the following **prioritized actions**:  \n### 1. Immediate Actions (Highest ROI - Implement in 0-3 months)  \n**1. log_org_size** (loading: 0.857)  \n- **Problem**: Larger organizations face scale challenges  \n- **Action**: Implement automation for repetitive security tasks  \n- **Target**: Maintain consistent security posture regardless of org size  \n**2. log_vuln_count** (loading: 0.853)  \n- **Problem**: High vulnerability counts indicate scanning or remediation gaps  \n- **Action**: Increase vulnerability scan frequency to weekly  \n- **Target**: Reduce total vulnerability count by 40% in 12 months  \n**3. log_security_incidents** (loading: 0.700)  \n- **Problem**: Lack of visibility into incident trends  \n- **Action**: Implement standardized incident reporting and tracking  \n- **Target**: Reduce mean time to detect (MTTD) to <1 hour  \n### 2. Medium-Term Investments (3-6 months, ~$100k-300k)  \n**log_org_size**: Scale security team proportionally (1 security FTE per 100 employees)  \n**log_vuln_count**: Create vulnerability management SLA: Critical (7 days), High (30 days)  \n**log_security_incidents**: Deploy SIEM for centralized security monitoring ($30k-100k/year)  \n### 3. Long-Term Strategic Initiatives (6-12 months, ~$300k-600k/year)  \n**log_org_size**: Build security centers of excellence for enterprise-wide consistency  \n**log_vuln_count**: Hire security engineer focused on vulnerability management ($130k-160k)  \n**log_security_incidents**: Build SOC capability with 24/7 monitoring  \n## Why These Matter  \n- **PC1** explains 20.5% of variance and correlates **0.688** with security incidents  \n- The top 5 variables loading on PC1 are directly actionable with clear interventions  \n- Improving these by 1 standard deviation could reduce incidents by approximately **60%**  \n## Department-Specific Focus  \n**Best Performer**: **Accounting** (average 0.0 incidents/quarter)  \n- Share their practices with other departments  \n- Document their success factors for replication  \n**Needs Most Attention**: **Sales** (average 3.8 incidents/quarter)  \n- Immediate intervention required  \n- Assign dedicated security resource for 90 days  \n- Implement quick wins from list above  \n### All Departments:  \n**Accounting**: 0.0 incidents/quarter (✓ Below average)  \n**Business Development**: 0.0 incidents/quarter (✓ Below average)  \n**Clinical Operations**: 1.2 incidents/quarter (⚠️ Above average)  \n**Compliance**: 0.0 incidents/quarter (✓ Below average)  \n**Customer Support**: 2.9 incidents/quarter (⚠️ Above average)  \n**Data Science**: 0.0 incidents/quarter (✓ Below average)  \n**DevOps**: 0.0 incidents/quarter (✓ Below average)  \n**E-commerce**: 0.5 incidents/quarter (✓ Below average)  \n**Engineering**: 0.0 incidents/quarter (✓ Below average)  \n**Facilities**: 1.1 incidents/quarter (⚠️ Above average)  \n**Field Services**: 0.0 incidents/quarter (✓ Below average)  \n**Finance**: 0.0 incidents/quarter (✓ Below average)  \n**HR**: 0.2 incidents/quarter (✓ Below average)  \n**IT**: 0.4 incidents/quarter (✓ Below average)  \n**Internal Audit**: 1.6 incidents/quarter (⚠️ Above average)  \n**Investor Relations**: 0.0 incidents/quarter (✓ Below average)  \n**Legal**: 0.5 incidents/quarter (✓ Below average)  \n**Logistics**: 1.9 incidents/quarter (⚠️ Above average)  \n**Marketing**: 0.0 incidents/quarter (✓ Below average)  \n**Operations**: 0.0 incidents/quarter (✓ Below average)  \n**Procurement**: 0.0 incidents/quarter (✓ Below average)  \n**Product**: 0.0 incidents/quarter (✓ Below average)  \n**Public Relations**: 0.5 incidents/quarter (✓ Below average)  \n**Quality Assurance**: 0.0 incidents/quarter (✓ Below average)  \n**R&D**: 0.4 incidents/quarter (✓ Below average)  \n**Risk Management**: 1.4 incidents/quarter (⚠️ Above average)  \n**Sales**: 3.8 incidents/quarter (⚠️ Above average)  \n**Security**: 0.0 incidents/quarter (✓ Below average)  \n**Supply Chain**: 0.0 incidents/quarter (✓ Below average)  \n**Training**: 1.5 incidents/quarter (⚠️ Above average)  \n## Resource Requirements  \nTo implement these recommendations:  \n| Timeline | Investment | Key Activities |  \n|----------|-----------|----------------|  \n| **Quick wins (0-3 months)** | $0-10k | Mandatory training, MFA for admins, phishing sims |  \n| **Medium-term (3-6 months)** | $100k-300k | 1-2 FTE hires, EDR deployment, CSPM tool |  \n| **Long-term (6-12 months)** | $300k-600k/year | Additional staff, enterprise tools, automation |  \n## Expected Outcomes  \n### Quantitative Targets (12-month goals):  \n- **Reduce security incidents by 60%** (from 0.6 to ~0.2 per dept/quarter)  \n- Achieve **100% MFA coverage** across all users  \n- Reduce **mean time to patch to <7 days** for critical vulnerabilities  \n- Increase **training completion to 95%+** organization-wide  \n- Reduce **phishing click rate to <5%**  \n### Return on Investment:  \n- **Annual incidents prevented**: ~1  \n- **Estimated annual savings**: $71,500 (at $50,000 per incident)  \n- **ROI**: ~-76% on medium-term investment  \n## Measuring Success  \nTrack these PC scores quarterly to monitor improvement:  \n- **Target**: Move all departments' PC1 scores closer to Accounting's profile  \n- **Dashboard**: Create quarterly PC score tracking with incident trends  \n- **Review**: Executive review of security posture using PC metrics (simpler than 11 individual metrics)  \n## Why PCA Was Valuable  \nRather than tracking 11 separate metrics independently, PCA showed us that:  \n1. **Most variation comes from just 8 underlying factors** - we can focus our attention  \n2. **We can prioritize resources** on variables that load heavily on incident-correlated PCs (PC1)  \n3. **We have a quantitative basis** for budget requests: \"Investing $300,000 in these 3 areas will reduce incidents by 60%\"  \n4. **Departments can be compared** fairly using PC scores rather than raw metrics that don't account for size/complexity  \nThis transforms cybersecurity from reactive firefighting to **proactive, data-driven risk management** with clear priorities and measurable outcomes.  \n## Next Steps  \n1. **Week 1**: Present findings to leadership, secure budget approval for quick wins  \n2. **Month 1**: Implement all quick wins, begin hiring for medium-term roles  \n3. **Month 3**: Deploy tools (EDR, CSPM), complete first round of enhanced training  \n4. **Month 6**: Review PC scores, measure incident reduction, adjust strategy  \n5. **Month 12**: Full program assessment, demonstrate ROI, plan next phase  \n---  \n*Analysis based on 240 department-quarter observations across 30 departments over 8 quarters.*  "
  },
  {
   "cell_type": "markdown",
   "id": "b049a4e8-b657-4717-bb0a-1e3a1230d94c",
   "metadata": {
    "name": "Conclusion",
    "collapsed": false
   },
   "source": "PCA successfully identified the underlying structure in our cybersecurity dataset. By no surprise, this reveals that organizational scale, security control effectiveness, and human factors are the primary dimensions of variation. This analysis provides a foundation for more sophisticated cybersecurity analytics, better resource allocation, and improved cybersecurity outcomes across the organization.\n\nThe reduction from eleven variables to eight components demonstrates that security metrics are interrelated in meaningful ways. Therefore, we can monitor organizational cybersecurity posture more efficiently using these composite dimensions rather than tracking all metrics independently.\n\nI really like what PCA does and how it results in useful and practical conclusions that are easily understandable by humans - allowing, in this case, for straightforward advice on how to improve our cybersecurity maturity to reduce organizational risk.\n\nSome notes:\n    o I transformed all highly skewed variables (more than in my original work on this data);\n    o I used only log transformations this time\n    o I left non-skewed variables in their original form and explained which variables were (only continuous variables were used)\n    o I verified the transformations worked\n\nMy goal was to assure the relationshipships between variables would be more linear and that no single variable can dominate due to extreme skewness.\n\nAlso, for specific product recommendations I suggest KnowBe4 for the phishing simulations, click rates and training tracking.\n\nFor e-mail security, I like a product such as Checkpoint Harmony."
  },
  {
   "cell_type": "markdown",
   "id": "95f5ea1d-e7cc-428a-a560-aa07996f883c",
   "metadata": {
    "name": "ScratchCommentary",
    "collapsed": false
   },
   "source": "Following, is a second approach to drawing my final conclusions and recommendations.  I left this in as it seemed the more I analyzed the better I was able to improve the model and, consequently, the specific recommendations (actionable insights)."
  },
  {
   "cell_type": "code",
   "id": "d4de536a-e97c-4c95-b07c-3022ee37df8b",
   "metadata": {
    "language": "python",
    "name": "ActionableInsightsCode2of2"
   },
   "outputs": [],
   "source": "# COMPREHENSIVE ANALYSIS WITH AUTO-GENERATED MARKDOWN CONCLUSION\n\nprint(\"=\" * 80)\nprint(\"DETAILED ANALYSIS FOR ACTIONABLE RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# PART 1: IDENTIFY KEY DRIVERS OF SECURITY INCIDENTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 1: WHAT DRIVES SECURITY INCIDENTS?\")\nprint(\"=\" * 80)\n\n#calculate correlation of each PC with security incidents\npc_incident_correlations = {}\nfor i in range(optimal_n):\n    pc_col = f'PC{i+1}'\n    corr = np.corrcoef(pca_df[pc_col], pca_df['security_incidents'])[0, 1]\n    pc_incident_correlations[pc_col] = corr\n    print(f\"\\n{pc_col} correlation with security incidents: {corr:.3f}\")\n    print(f\"  Variance explained: {explained_variance[i]:.1%}\")\n\n#find most important PC (highest correlation with incidents)\nmost_correlated_pc_name = max(pc_incident_correlations, key=lambda k: abs(pc_incident_correlations[k]))\nmost_correlated_pc_idx = int(most_correlated_pc_name.replace('PC', '')) - 1\nmost_correlated_pc_corr = pc_incident_correlations[most_correlated_pc_name]\n\nprint(f\"\\n>>> MOST IMPORTANT: {most_correlated_pc_name}\")\nprint(f\"    Correlation with incidents: {most_correlated_pc_corr:.3f}\")\nprint(f\"    Variance explained: {explained_variance[most_correlated_pc_idx]:.1%}\")\n\n# ============================================================================\n# PART 2: IDENTIFY TOP VARIABLES TO ADDRESS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 2: TOP VARIABLES THAT NEED ATTENTION\")\nprint(\"=\" * 80)\n\n#get top 5 variables by absolute loading on most important PC\ntop_5_vars = loadings_df.iloc[:, most_correlated_pc_idx].abs().sort_values(ascending=False).head(5)\n\nprint(f\"\\nTop 5 variables loading on {most_correlated_pc_name}:\")\ntop_vars_list = []\nfor rank, (var, abs_loading) in enumerate(top_5_vars.items(), 1):\n    actual_loading = loadings_df.loc[var, most_correlated_pc_name]\n    direction = \"Higher\" if actual_loading * most_correlated_pc_corr > 0 else \"Lower\"\n    effect = \"MORE incidents\" if actual_loading * most_correlated_pc_corr > 0 else \"FEWER incidents\"\n    \n    print(f\"\\n{rank}. {var}\")\n    print(f\"   Loading: {actual_loading:.3f}\")\n    print(f\"   Effect: {direction} values → {effect}\")\n    \n    top_vars_list.append({\n        'rank': rank,\n        'variable': var,\n        'loading': actual_loading,\n        'abs_loading': abs_loading,\n        'direction': direction,\n        'effect': effect\n    })\n\n# ============================================================================\n# PART 3: SPECIFIC ACTIONABLE RECOMMENDATIONS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 3: SPECIFIC, ACTIONABLE RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\n#detailed recommendations for each variable\nrecommendations_detailed = {\n    'log_mean_time_to_patch': {\n        'problem': 'Slow patching increases vulnerability window',\n        'quick_win': 'Prioritize critical patches, automate patch deployment for 30% of systems',\n        'medium': 'Hire 1-2 dedicated patch management specialists ($120k-150k/year)',\n        'long': 'Implement enterprise patch management system ($50k tool + 2 FTE)',\n        'metric': 'Reduce mean time to patch from current to <7 days for critical patches'\n    },\n    'log_vuln_count': {\n        'problem': 'High vulnerability counts indicate scanning or remediation gaps',\n        'quick_win': 'Increase vulnerability scan frequency to weekly',\n        'medium': 'Create vulnerability management SLA: Critical (7 days), High (30 days)',\n        'long': 'Hire security engineer focused on vulnerability management ($130k-160k)',\n        'metric': 'Reduce total vulnerability count by 40% in 12 months'\n    },\n    'training_completion_rate': {\n        'problem': 'Incomplete training leaves users vulnerable to social engineering',\n        'quick_win': 'Make security training mandatory with executive sponsorship',\n        'medium': 'Implement quarterly micro-learning modules (10 min each)',\n        'long': 'Gamify training with rewards, track completion in performance reviews',\n        'metric': 'Achieve 95%+ completion rate within 6 months'\n    },\n    'phishing_sim_click_rate': {\n        'problem': 'High click rates indicate users are vulnerable to phishing',\n        'quick_win': 'Run monthly phishing simulations with immediate educational pop-ups',\n        'medium': 'Implement targeted training for repeat clickers',\n        'long': 'Deploy email security solution with URL rewriting and sandboxing ($15-20/user/year)',\n        'metric': 'Reduce click rate from current to <5% organization-wide'\n    },\n    'mfa_coverage': {\n        'problem': 'Accounts without MFA are vulnerable to credential compromise',\n        'quick_win': 'Mandate MFA for all admin and privileged accounts (immediate)',\n        'medium': 'Require MFA for all users accessing corporate resources (90 days)',\n        'long': 'Implement passwordless authentication (FIDO2) for 50% of users',\n        'metric': 'Achieve 100% MFA coverage for all users within 3 months'\n    },\n    'endpoint_coverage': {\n        'problem': 'Unprotected endpoints are entry points for malware',\n        'quick_win': 'Audit all endpoints, identify gaps, create deployment plan',\n        'medium': 'Deploy EDR to remaining endpoints ($40-60/endpoint/year)',\n        'long': 'Implement zero-trust architecture with continuous endpoint verification',\n        'metric': 'Achieve 100% endpoint coverage within 6 months'\n    },\n    'log_login_failures': {\n        'problem': 'High login failures may indicate brute force attacks or poor UX',\n        'quick_win': 'Implement account lockout after 5 failed attempts',\n        'medium': 'Deploy password manager to all users ($5-10/user/year)',\n        'long': 'Implement SSO with adaptive authentication',\n        'metric': 'Reduce login failures by 60% through better UX and security'\n    },\n    'log_cloud_misconfig': {\n        'problem': 'Cloud misconfigurations expose data and services',\n        'quick_win': 'Run immediate cloud security audit using free tools',\n        'medium': 'Implement Cloud Security Posture Management (CSPM) tool ($20k-50k/year)',\n        'long': 'Hire cloud security engineer or consultant ($140k-180k or $200/hr)',\n        'metric': 'Reduce misconfigurations by 80%, maintain <5 open issues'\n    },\n    'it_budget_per_emp': {\n        'problem': 'Insufficient budget limits security program effectiveness',\n        'quick_win': 'Document current budget gaps with business risk analysis',\n        'medium': 'Request 20-30% budget increase with ROI justification',\n        'long': 'Benchmark against industry standards, align budget to risk appetite',\n        'metric': 'Increase security budget to $X per employee (industry median)'\n    },\n    'log_org_size': {\n        'problem': 'Larger organizations face scale challenges',\n        'quick_win': 'Implement automation for repetitive security tasks',\n        'medium': 'Scale security team proportionally (1 security FTE per 100 employees)',\n        'long': 'Build security centers of excellence for enterprise-wide consistency',\n        'metric': 'Maintain consistent security posture regardless of org size'\n    },\n    'log_security_incidents': {\n        'problem': 'Lack of visibility into incident trends',\n        'quick_win': 'Implement standardized incident reporting and tracking',\n        'medium': 'Deploy SIEM for centralized security monitoring ($30k-100k/year)',\n        'long': 'Build SOC capability with 24/7 monitoring',\n        'metric': 'Reduce mean time to detect (MTTD) to <1 hour'\n    }\n}\n\nprint(\"\\nDETAILED RECOMMENDATIONS FOR TOP 5 DRIVERS:\\n\")\nfor item in top_vars_list:\n    var = item['variable']\n    rank = item['rank']\n    loading = item['loading']\n    direction = item['direction']\n    \n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        print(f\"\\n{'='*70}\")\n        print(f\"#{rank}: {var} (loading: {loading:.3f})\")\n        print(f\"{'='*70}\")\n        print(f\"PROBLEM: {rec['problem']}\")\n        print(f\"\\n→ QUICK WIN (0-3 months, low cost):\")\n        print(f\"  {rec['quick_win']}\")\n        print(f\"\\n→ MEDIUM-TERM (3-6 months, moderate investment):\")\n        print(f\"  {rec['medium']}\")\n        print(f\"\\n→ LONG-TERM (6-12 months, significant investment):\")\n        print(f\"  {rec['long']}\")\n        print(f\"\\n→ SUCCESS METRIC:\")\n        print(f\"  {rec['metric']}\")\n\n# ============================================================================\n# PART 4: DEPARTMENT-SPECIFIC RECOMMENDATIONS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 4: DEPARTMENT-SPECIFIC RECOMMENDATIONS\")\nprint(\"=\" * 80)\n\ndept_pc_means = pca_df.groupby('department')[[f'PC{i+1}' for i in range(min(3, optimal_n))]].mean()\ndept_incidents = pca_df.groupby('department')['security_incidents'].mean()\n\nprint(\"\\nDepartment Profiles:\")\nprint(\"-\" * 70)\ndept_analysis = pd.concat([dept_pc_means, dept_incidents], axis=1)\nprint(dept_analysis.round(2))\n\n#identify best and worst performers\nbest_dept = dept_incidents.idxmin()\nworst_dept = dept_incidents.idxmax()\n\nprint(f\"\\n>>> BEST PERFORMER: {best_dept}\")\nprint(f\"    Average incidents: {dept_incidents[best_dept]:.1f}\")\nprint(f\"    PC scores: {dept_pc_means.loc[best_dept].to_dict()}\")\n\nprint(f\"\\n>>> NEEDS MOST ATTENTION: {worst_dept}\")\nprint(f\"    Average incidents: {dept_incidents[worst_dept]:.1f}\")\nprint(f\"    PC scores: {dept_pc_means.loc[worst_dept].to_dict()}\")\n\nprint(f\"\\nRECOMMENDATION: Have {best_dept} share best practices with {worst_dept}\")\n\n#specific recommendations by department\nprint(\"\\n\" + \"-\" * 70)\nprint(\"DEPARTMENT-SPECIFIC ACTION PLANS:\")\nprint(\"-\" * 70)\n\nfor dept in dept_pc_means.index:\n    print(f\"\\n{dept.upper()}:\")\n    pc1_score = dept_pc_means.loc[dept, 'PC1']\n    pc2_score = dept_pc_means.loc[dept, 'PC2'] if 'PC2' in dept_pc_means.columns else 0\n    avg_incidents = dept_incidents[dept]\n    \n    print(f\"  Current incidents/quarter: {avg_incidents:.1f}\")\n    print(f\"  PC1 score: {pc1_score:.2f} | PC2 score: {pc2_score:.2f}\")\n    \n    #interpret PC1\n    if pc1_score > 0.5:\n        print(f\"  • Large/complex organization - prioritize automation and additional staff\")\n    elif pc1_score < -0.5:\n        print(f\"  • Smaller organization - focus on foundational controls first\")\n    \n    #interpret PC2 if available\n    if 'PC2' in dept_pc_means.columns:\n        if pc2_score < -0.5:\n            print(f\"  • WEAK controls - PRIORITY: improve coverage metrics (MFA, endpoints)\")\n        elif pc2_score > 0.5:\n            print(f\"  • STRONG controls - maintain and focus on advanced threats\")\n    \n    #compare to org average\n    if avg_incidents > dept_incidents.mean():\n        print(f\"  ⚠️  ABOVE AVERAGE INCIDENTS - needs immediate attention\")\n    else:\n        print(f\"  ✓  Below average incidents - share practices with other teams\")\n\n# ============================================================================\n# PART 5: ROI AND IMPACT ESTIMATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 5: ESTIMATED IMPACT AND ROI\")\nprint(\"=\" * 80)\n\ncurrent_mean_incidents = pca_df['security_incidents'].mean()\ncurrent_total_incidents = pca_df['security_incidents'].sum()\nn_dept_quarters = len(pca_df)\n\nprint(f\"\\nCURRENT STATE:\")\nprint(f\"  Average incidents per dept/quarter: {current_mean_incidents:.1f}\")\nprint(f\"  Total incidents in dataset: {current_total_incidents:.0f}\")\nprint(f\"  Number of observations: {n_dept_quarters}\")\n\n#estimate impact based on correlation\ncorrelation_strength = abs(most_correlated_pc_corr)\nestimated_reduction_pct = min(correlation_strength * 100, 60)  # Cap at 60%\n\nprint(f\"\\nESTIMATED IMPACT:\")\nprint(f\"  {most_correlated_pc_name} correlation with incidents: {most_correlated_pc_corr:.3f}\")\nprint(f\"  By improving top 3-5 factors by 1 standard deviation:\")\nprint(f\"    • Expected incident reduction: ~{estimated_reduction_pct:.0f}%\")\nprint(f\"    • From {current_mean_incidents:.1f} to ~{current_mean_incidents * (1 - estimated_reduction_pct/100):.1f} incidents/quarter\")\nprint(f\"    • Annual reduction: ~{current_mean_incidents * 4 * estimated_reduction_pct/100:.0f} fewer incidents/year\")\n\n#cost-benefit\nprint(f\"\\nESTIMATED COSTS:\")\nprint(f\"  Quick wins: $0-10k (reallocate existing resources)\")\nprint(f\"  Medium-term: $100k-300k (tools + 1-2 FTE)\")\nprint(f\"  Long-term: $300k-600k/year (comprehensive program)\")\n\nprint(f\"\\nESTIMATED BENEFITS (assuming $50k cost per incident):\")\nincidents_prevented = current_mean_incidents * 4 * estimated_reduction_pct / 100\ncost_per_incident = 50000  # Adjust this for your organization\nannual_savings = incidents_prevented * cost_per_incident\n\nprint(f\"  Incidents prevented per year: ~{incidents_prevented:.0f}\")\nprint(f\"  Annual cost savings: ${annual_savings:,.0f}\")\nprint(f\"  ROI: {(annual_savings / 300000 - 1) * 100:.0f}% (against medium-term investment)\")\n\n# ============================================================================\n# PART 6: AUTO-GENERATE MARKDOWN CONCLUSION\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"AUTO-GENERATED MARKDOWN CONCLUSION (COPY-PASTE BELOW)\")\nprint(\"=\" * 80)\n\n#interpret what PC1 and PC2 represent based on loadings\npc1_top_var = loadings_df.iloc[:, 0].abs().idxmax()\npc1_interpretation = \"organizational scale and security complexity\"\nif 'training' in pc1_top_var or 'phishing' in pc1_top_var:\n    pc1_interpretation = \"human factor vulnerabilities and training effectiveness\"\nelif 'coverage' in pc1_top_var or 'mfa' in pc1_top_var:\n    pc1_interpretation = \"security control coverage and maturity\"\n\npc2_interpretation = \"security hygiene and response effectiveness\"\nif optimal_n >= 2:\n    pc2_top_var = loadings_df.iloc[:, 1].abs().idxmax()\n    if 'patch' in pc2_top_var or 'vuln' in pc2_top_var:\n        pc2_interpretation = \"vulnerability management and patching speed\"\n\nmarkdown_output = f\"\"\"\n# Conclusion: Actionable Insights from PCA\n\n## What We Learned\n\nThis PCA analysis revealed that **{optimal_n} principal components** capture **{cumulative_variance[optimal_n-1]:.1%}** of the variance in our cybersecurity data, with **PC1 primarily representing {pc1_interpretation}**, explaining **{explained_variance[0]:.1%}** of the variance.\n\nThe analysis successfully reduced our monitoring from 11 separate metrics to {optimal_n} composite dimensions that capture the essential patterns in our security posture.\n\n## Key Finding: What Drives Security Incidents\n\n**{most_correlated_pc_name} shows the strongest relationship with security incidents** (correlation: **{most_correlated_pc_corr:.3f}**), explaining **{explained_variance[most_correlated_pc_idx]:.1%}** of variance. This tells us that focusing on the variables that load heavily on {most_correlated_pc_name} will have the greatest impact on reducing incidents.\n\n## Specific Recommendations (Prioritized by Impact)\n\nBased on the PCA loadings and their correlation with security incidents, we identified the following **prioritized actions**:\n\n### 1. Immediate Actions (Highest ROI - Implement in 0-3 months)\n\"\"\"\n\nfor item in top_vars_list[:3]:\n    var = item['variable']\n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        markdown_output += f\"\"\"\n**{item['rank']}. {var}** (loading: {item['loading']:.3f})\n- **Problem**: {rec['problem']}\n- **Action**: {rec['quick_win']}\n- **Target**: {rec['metric']}\n\"\"\"\n\nmarkdown_output += f\"\"\"\n### 2. Medium-Term Investments (3-6 months, ~$100k-300k)\n\"\"\"\n\nfor item in top_vars_list[:3]:\n    var = item['variable']\n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        markdown_output += f\"\"\"\n**{var}**: {rec['medium']}\n\"\"\"\n\nmarkdown_output += f\"\"\"\n### 3. Long-Term Strategic Initiatives (6-12 months, ~$300k-600k/year)\n\"\"\"\n\nfor item in top_vars_list[:3]:\n    var = item['variable']\n    if var in recommendations_detailed:\n        rec = recommendations_detailed[var]\n        markdown_output += f\"\"\"\n**{var}**: {rec['long']}\n\"\"\"\n\nmarkdown_output += f\"\"\"\n## Why These Matter\n\n- **{most_correlated_pc_name}** explains {explained_variance[most_correlated_pc_idx]:.1%} of variance and correlates **{most_correlated_pc_corr:.3f}** with security incidents\n- The top {len(top_vars_list)} variables loading on {most_correlated_pc_name} are directly actionable with clear interventions\n- Improving these by 1 standard deviation could reduce incidents by approximately **{estimated_reduction_pct:.0f}%**\n\n## Department-Specific Focus\n\n**Best Performer**: **{best_dept}** (average {dept_incidents[best_dept]:.1f} incidents/quarter)\n- Share their practices with other departments\n- Document their success factors for replication\n\n**Needs Most Attention**: **{worst_dept}** (average {dept_incidents[worst_dept]:.1f} incidents/quarter)\n- Immediate intervention required\n- Assign dedicated security resource for 90 days\n- Implement quick wins from list above\n\n### All Departments:\n\"\"\"\n\nfor dept in dept_pc_means.index:\n    avg_incidents = dept_incidents[dept]\n    pc1_score = dept_pc_means.loc[dept, 'PC1']\n    status = \"⚠️ Above average\" if avg_incidents > dept_incidents.mean() else \"✓ Below average\"\n    \n    markdown_output += f\"\"\"\n**{dept}**: {avg_incidents:.1f} incidents/quarter ({status})\n\"\"\"\n\nmarkdown_output += f\"\"\"\n## Resource Requirements\n\nTo implement these recommendations:\n\n| Timeline | Investment | Key Activities |\n|----------|-----------|----------------|\n| **Quick wins (0-3 months)** | $0-10k | Mandatory training, MFA for admins, phishing sims |\n| **Medium-term (3-6 months)** | $100k-300k | 1-2 FTE hires, EDR deployment, CSPM tool |\n| **Long-term (6-12 months)** | $300k-600k/year | Additional staff, enterprise tools, automation |\n\n## Expected Outcomes\n\n### Quantitative Targets (12-month goals):\n- **Reduce security incidents by {estimated_reduction_pct:.0f}%** (from {current_mean_incidents:.1f} to ~{current_mean_incidents * (1 - estimated_reduction_pct/100):.1f} per dept/quarter)\n- Achieve **100% MFA coverage** across all users\n- Reduce **mean time to patch to <7 days** for critical vulnerabilities\n- Increase **training completion to 95%+** organization-wide\n- Reduce **phishing click rate to <5%**\n\n### Return on Investment:\n- **Annual incidents prevented**: ~{incidents_prevented:.0f}\n- **Estimated annual savings**: ${annual_savings:,.0f} (at ${cost_per_incident:,} per incident)\n- **ROI**: ~{(annual_savings / 300000 - 1) * 100:.0f}% on medium-term investment\n\n## Measuring Success\n\nTrack these PC scores quarterly to monitor improvement:\n\n- **Target**: Move all departments' {most_correlated_pc_name} scores closer to {best_dept}'s profile\n- **Dashboard**: Create quarterly PC score tracking with incident trends\n- **Review**: Executive review of security posture using PC metrics (simpler than 11 individual metrics)\n\n## Why PCA Was Valuable\n\nRather than tracking 11 separate metrics independently, PCA showed us that:\n\n1. **Most variation comes from just {optimal_n} underlying factors** - we can focus our attention\n2. **We can prioritize resources** on variables that load heavily on incident-correlated PCs ({most_correlated_pc_name})\n3. **We have a quantitative basis** for budget requests: \"Investing ${300000:,} in these {len(top_vars_list[:3])} areas will reduce incidents by {estimated_reduction_pct:.0f}%\"\n4. **Departments can be compared** fairly using PC scores rather than raw metrics that don't account for size/complexity\n\nThis transforms cybersecurity from reactive firefighting to **proactive, data-driven risk management** with clear priorities and measurable outcomes.\n\n## Next Steps\n\n1. **Week 1**: Present findings to leadership, secure budget approval for quick wins\n2. **Month 1**: Implement all quick wins, begin hiring for medium-term roles\n3. **Month 3**: Deploy tools (EDR, CSPM), complete first round of enhanced training\n4. **Month 6**: Review PC scores, measure incident reduction, adjust strategy\n5. **Month 12**: Full program assessment, demonstrate ROI, plan next phase\n\n---\n\n*Analysis based on {n_dept_quarters} department-quarter observations across {len(pca_df['department'].unique())} departments over {len(pca_df['quarter'].unique())} quarters.*\n\"\"\"\n\n#print(markdown_output) - commented out once I grabbed the markdown and placed into a separate cell below\n\n# Save to file for easy copying\nwith open('PCA_Conclusion_AutoGenerated.md', 'w') as f:\n    f.write(markdown_output)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✓ Markdown conclusion saved to: PCA_Conclusion_AutoGenerated.md and pasted to markdown cell below:\")\nprint(\"=\" * 80)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "03edb1ef-b1b2-4839-bf03-633b5bb3d012",
   "metadata": {
    "name": "ActionableInsightsCommentary2of2",
    "collapsed": false
   },
   "source": "# Conclusion: Actionable Insights from PCA  \n## What We Learned  \nThis PCA analysis revealed that **8 principal components** capture **91.7%** of the variance in our cybersecurity data, with **PC1 primarily representing organizational scale and security complexity**, explaining **20.5%** of the variance.  \nThe analysis successfully reduced our monitoring from 11 separate metrics to 8 composite dimensions that capture the essential patterns in our security posture.  \n## Key Finding: What Drives Security Incidents  \n**PC1 shows the strongest relationship with security incidents** (correlation: **0.688**), explaining **20.5%** of variance. This tells us that focusing on the variables that load heavily on PC1 will have the greatest impact on reducing incidents.  \n## Specific Recommendations (Prioritized by Impact)  \nBased on the PCA loadings and their correlation with security incidents, we identified the following **prioritized actions**:  \n### 1. Immediate Actions (Highest ROI - Implement in 0-3 months)  \n**1. log_org_size** (loading: 0.857)  \n- **Problem**: Larger organizations face scale challenges  \n- **Action**: Implement automation for repetitive security tasks  \n- **Target**: Maintain consistent security posture regardless of org size  \n**2. log_vuln_count** (loading: 0.853)  \n- **Problem**: High vulnerability counts indicate scanning or remediation gaps  \n- **Action**: Increase vulnerability scan frequency to weekly  \n- **Target**: Reduce total vulnerability count by 40% in 12 months  \n**3. log_security_incidents** (loading: 0.700)  \n- **Problem**: Lack of visibility into incident trends  \n- **Action**: Implement standardized incident reporting and tracking  \n- **Target**: Reduce mean time to detect (MTTD) to <1 hour  \n### 2. Medium-Term Investments (3-6 months, ~$100k-300k)  \n**log_org_size**: Scale security team proportionally (1 security FTE per 100 employees)  \n**log_vuln_count**: Create vulnerability management SLA: Critical (7 days), High (30 days)  \n**log_security_incidents**: Deploy SIEM for centralized security monitoring ($30k-100k/year)  \n### 3. Long-Term Strategic Initiatives (6-12 months, ~$300k-600k/year)  \n**log_org_size**: Build security centers of excellence for enterprise-wide consistency  \n**log_vuln_count**: Hire security engineer focused on vulnerability management ($130k-160k)  \n**log_security_incidents**: Build SOC capability with 24/7 monitoring  \n## Why These Matter  \n- **PC1** explains 20.5% of variance and correlates **0.688** with security incidents  \n- The top 5 variables loading on PC1 are directly actionable with clear interventions  \n- Improving these by 1 standard deviation could reduce incidents by approximately **60%**  \n## Department-Specific Focus  \n**Best Performer**: **Accounting** (average 0.0 incidents/quarter)  \n- Share their practices with other departments  \n- Document their success factors for replication  \n**Needs Most Attention**: **Sales** (average 3.8 incidents/quarter)  \n- Immediate intervention required  \n- Assign dedicated security resource for 90 days  \n- Implement quick wins from list above  \n### All Departments:  \n**Accounting**: 0.0 incidents/quarter (✓ Below average)  \n**Business Development**: 0.0 incidents/quarter (✓ Below average)  \n**Clinical Operations**: 1.2 incidents/quarter (⚠️ Above average)  \n**Compliance**: 0.0 incidents/quarter (✓ Below average)  \n**Customer Support**: 2.9 incidents/quarter (⚠️ Above average)  \n**Data Science**: 0.0 incidents/quarter (✓ Below average)  \n**DevOps**: 0.0 incidents/quarter (✓ Below average)  \n**E-commerce**: 0.5 incidents/quarter (✓ Below average)  \n**Engineering**: 0.0 incidents/quarter (✓ Below average)  \n**Facilities**: 1.1 incidents/quarter (⚠️ Above average)  \n**Field Services**: 0.0 incidents/quarter (✓ Below average)  \n**Finance**: 0.0 incidents/quarter (✓ Below average)  \n**HR**: 0.2 incidents/quarter (✓ Below average)  \n**IT**: 0.4 incidents/quarter (✓ Below average)  \n**Internal Audit**: 1.6 incidents/quarter (⚠️ Above average)  \n**Investor Relations**: 0.0 incidents/quarter (✓ Below average)  \n**Legal**: 0.5 incidents/quarter (✓ Below average)  \n**Logistics**: 1.9 incidents/quarter (⚠️ Above average)  \n**Marketing**: 0.0 incidents/quarter (✓ Below average)  \n**Operations**: 0.0 incidents/quarter (✓ Below average)  \n**Procurement**: 0.0 incidents/quarter (✓ Below average)  \n**Product**: 0.0 incidents/quarter (✓ Below average)  \n**Public Relations**: 0.5 incidents/quarter (✓ Below average)  \n**Quality Assurance**: 0.0 incidents/quarter (✓ Below average)  \n**R&D**: 0.4 incidents/quarter (✓ Below average)  \n**Risk Management**: 1.4 incidents/quarter (⚠️ Above average)  \n**Sales**: 3.8 incidents/quarter (⚠️ Above average)  \n**Security**: 0.0 incidents/quarter (✓ Below average)  \n**Supply Chain**: 0.0 incidents/quarter (✓ Below average)  \n**Training**: 1.5 incidents/quarter (⚠️ Above average)  \n## Resource Requirements  \nTo implement these recommendations:  \n| Timeline | Investment | Key Activities |  \n|----------|-----------|----------------|  \n| **Quick wins (0-3 months)** | $0-10k | Mandatory training, MFA for admins, phishing sims |  \n| **Medium-term (3-6 months)** | $100k-300k | 1-2 FTE hires, EDR deployment, CSPM tool |  \n| **Long-term (6-12 months)** | $300k-600k/year | Additional staff, enterprise tools, automation |  \n## Expected Outcomes  \n### Quantitative Targets (12-month goals):  \n- **Reduce security incidents by 60%** (from 0.6 to ~0.2 per dept/quarter)  \n- Achieve **100% MFA coverage** across all users  \n- Reduce **mean time to patch to <7 days** for critical vulnerabilities  \n- Increase **training completion to 95%+** organization-wide  \n- Reduce **phishing click rate to <5%**  \n### Return on Investment:  \n- **Annual incidents prevented**: ~1  \n- **Estimated annual savings**: $71,500 (at $50,000 per incident)  \n- **ROI**: ~-76% on medium-term investment  \n## Measuring Success  \nTrack these PC scores quarterly to monitor improvement:  \n- **Target**: Move all departments' PC1 scores closer to Accounting's profile  \n- **Dashboard**: Create quarterly PC score tracking with incident trends  \n- **Review**: Executive review of security posture using PC metrics (simpler than 11 individual metrics)  \n## Why PCA Was Valuable  \nRather than tracking 11 separate metrics independently, PCA showed us that:  \n1. **Most variation comes from just 8 underlying factors** - we can focus our attention  \n2. **We can prioritize resources** on variables that load heavily on incident-correlated PCs (PC1)  \n3. **We have a quantitative basis** for budget requests: \"Investing $300,000 in these 3 areas will reduce incidents by 60%\"  \n4. **Departments can be compared** fairly using PC scores rather than raw metrics that don't account for size/complexity  \nThis transforms cybersecurity from reactive firefighting to **proactive, data-driven risk management** with clear priorities and measurable outcomes.  \n## Next Steps  \n1. **Week 1**: Present findings to leadership, secure budget approval for quick wins  \n2. **Month 1**: Implement all quick wins, begin hiring for medium-term roles  \n3. **Month 3**: Deploy tools (EDR, CSPM), complete first round of enhanced training  \n4. **Month 6**: Review PC scores, measure incident reduction, adjust strategy  \n5. **Month 12**: Full program assessment, demonstrate ROI, plan next phase  \n---  \n*Analysis based on 240 department-quarter observations across 30 departments over 8 quarters.*  "
  }
 ]
}