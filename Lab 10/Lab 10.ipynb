{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "qg2s7m4dzhcdkstifnee",
   "authorId": "2206420187358",
   "authorName": "GREGSULLIVAN",
   "authorEmail": "gregsullivan@ciosoglobal.com",
   "sessionId": "408dc08e-b31d-4cab-b4fa-9673cbe7ce83",
   "lastEditTime": 1762114508965
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e174c6-e514-4682-8e4f-a45b47793715",
   "metadata": {
    "name": "intro",
    "collapsed": false
   },
   "source": "# Lab 10 - Predicting Patient Experience LTR\n\nHospitals are required to survey a certain number of patients and gather feedback on the experience they had with their visit:\n* Was the hospital clean? (1-10)\n* Did the staff communicate well with you? (1-10)\n* Were the staff friendly? (1-10)\n* Did you receive care in a timely manner? (1-10)\n* Where the instructions you were discharged with clear to you? (1-10)\n* **Would you recommend this facility to friends and family?** <- The \"likely to recommend\" (LTR): Yes or No\n\nThat last part is the most important. It determines federal reimbursement rates, gets published by rating services, and drives future patient volume. Anything you can do to improve LTR is a good thing.\n\nBut what factors influence LTR the most? We have some more detailed data in the other questions. We can use logistic regression to take the detailed ratings and build a model that predicts the LTR outcome: Yes or No."
  },
  {
   "cell_type": "code",
   "id": "ec84f038-bdaf-472f-acac-be2ec498de7c",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport streamlit as st\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22fd882d-0c60-425f-8948-3d0b10f0c1bd",
   "metadata": {
    "name": "_1_data",
    "collapsed": false
   },
   "source": "## 1. Read the data"
  },
  {
   "cell_type": "code",
   "id": "138dde90-7812-42a9-8657-367d1e5f1ba7",
   "metadata": {
    "language": "python",
    "name": "data"
   },
   "outputs": [],
   "source": "px = pd.read_csv('patient_experience.csv')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "718b4b8d-52f3-4ecb-af9f-a0b118ad7b07",
   "metadata": {
    "name": "_2_explore",
    "collapsed": false
   },
   "source": "## 2. Explore and Visualize the Data\n\nUseful things will be correlation scatterplots, histograms, by LTR series"
  },
  {
   "cell_type": "code",
   "id": "7fcfbb61-53a1-4e22-9e95-ef4120dc0ef3",
   "metadata": {
    "language": "python",
    "name": "explore"
   },
   "outputs": [],
   "source": "# Seaborn pairplot is perfect for this\n#   * hue='LTR' to show the LTR data sets as separate colors\n#   * diag_kind='kde' helps us see if the inputs are normalized or need to be transformed\n\nsns.pairplot(px, hue='LTR', diag_kind='kde')\nplt.suptitle(\"Patient Experience Variables by LTR\", y=1.02)\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "967159b8-7111-4310-9f1e-b7ba7b7de734",
   "metadata": {
    "name": "_3_split_and_model",
    "collapsed": false
   },
   "source": "## 3. Split and Model\n\n1. Scale the data\n2. Split the data into training (70%) and test (30%)\n3. Fit a Logistic Regression model"
  },
  {
   "cell_type": "code",
   "id": "420affd4-a92b-4561-8039-ac0159d91db1",
   "metadata": {
    "language": "python",
    "name": "scale"
   },
   "outputs": [],
   "source": "# separate independent and dependent variables\nX = px[['cleanliness','communication','staff_friendliness','timeliness','discharge_clarity']]\ny = px['LTR']\n\n# apply a standard scaler to normlize the values of each input variable\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b08ef59-4253-434f-807c-249651570495",
   "metadata": {
    "language": "python",
    "name": "split"
   },
   "outputs": [],
   "source": "# Keep 30% for testing\n# Pick any value you want for the random_state, but this keeps the work repeatable\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f496947-de07-4629-a13a-689cda0839b8",
   "metadata": {
    "language": "python",
    "name": "fit",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model = LogisticRegression()\nmodel.fit(X_train, y_train)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5955586-1f14-4e3b-9793-b879f45b0d48",
   "metadata": {
    "name": "_4_review_model",
    "collapsed": false
   },
   "source": "## 4. Review the Model\n\nTake a minute to look at the model coefficients and odds_ratios. What do they mean? Provide and interpretation."
  },
  {
   "cell_type": "code",
   "id": "912c15d9-5c78-4aa7-adc1-c96b8fd91e70",
   "metadata": {
    "language": "python",
    "name": "review"
   },
   "outputs": [],
   "source": "print(\"Intercept:\", model.intercept_)\nprint(\"Coefficients:\", model.coef_)\n\n# Create dataframe of coefficients\ncoef_df = pd.DataFrame({\n    'Variable': X.columns,\n    'Coefficient': model.coef_[0],\n    'Odds_Ratio': np.exp(model.coef_[0])\n})\nprint(\"\\nCoefficient Summary:\")\nprint(coef_df.sort_values('Coefficient', ascending=False))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40a84275-c7f2-4e11-8f2f-1e8d23ac889e",
   "metadata": {
    "name": "_4_interpret",
    "collapsed": false
   },
   "source": "What does this tell us?"
  },
  {
   "cell_type": "markdown",
   "id": "7bc17c66-6aa8-430a-b91f-bf3c93b4646c",
   "metadata": {
    "name": "_5_evaluate_model",
    "collapsed": false
   },
   "source": "## 5. Evaluate the Model\n\nUse tools like a confusion matrix and ROC/AUC curve to show how useful the model is."
  },
  {
   "cell_type": "code",
   "id": "9b8f1d84-3e09-4bb7-ace5-a7bbcb06206a",
   "metadata": {
    "language": "python",
    "name": "confusion_matrix"
   },
   "outputs": [],
   "source": "y_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)[:,1]\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc90fb1b-ba9b-4f48-9e8c-8c51cbaeb7a0",
   "metadata": {
    "language": "python",
    "name": "roc_auc",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fpr, tpr, _ = roc_curve(y_test, y_prob)\nauc = roc_auc_score(y_test, y_prob)\n\nplt.figure()\nplt.plot(fpr, tpr, label=f\"ROC curve (AUC = {auc:.2f})\")\nplt.plot([0,1], [0,1], linestyle='--', color='gray')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "760043df-736f-4937-a86d-e5ec2d178bd9",
   "metadata": {
    "name": "_6_predicted_prob",
    "collapsed": false
   },
   "source": "## 6. Predicted Probabilities\n\nWe can also visualize how each variable influences the LTR outcome as separate logit charts"
  },
  {
   "cell_type": "code",
   "id": "7ac3e513-931a-441c-828c-2de08faa6bc3",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "px.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f695c06f-ecaa-4a94-8c2e-d60c1b394bd2",
   "metadata": {
    "language": "python",
    "name": "all_probabilities"
   },
   "outputs": [],
   "source": "# The value range for each input is 1 to 10\nvalue_range = np.linspace(1, 10, 50)\n\n# We'll provide a default value of 7 for the other variables being held constant\ndefault_val = [7]*50\nstarter = pd.DataFrame({\n    'cleanliness': default_val,\n    'communication': default_val,\n    'staff_friendliness': default_val,\n    'timeliness': default_val,\n    'discharge_clarity': default_val\n})\n\n\n# Loop through all fields and create a predictions for all possible inputs\nfor field in starter.keys():\n    example = pd.DataFrame()\n    for c in starter.keys():\n        if c == field:\n            example[c] = value_range\n        else:\n            example[c] = default_val\n\n    example_scaled = scaler.transform(example)\n    example['predicted_prob'] = model.predict_proba(example_scaled)[:,1]\n\n    sns.lineplot(x=field, y='predicted_prob', data=example)\n    plt.ylim(0,1)\n    plt.title(f\"Effect of {field} on Probability of LTR\")\n    plt.ylabel(\"Predicted Probability (LTR=1)\")\n    plt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39482c93-d2a5-4ca6-8784-175b25ad58da",
   "metadata": {
    "name": "WouldIRecommend",
    "collapsed": false
   },
   "source": "## 7. Making Predictions for New Patients\n\nNow that I have a trained model, I can use it to predict whether a new patient \nwould recommend the hospital based on their survey responses.\n\n**Business Question:** Would this patient recommend our facility? (Yes or No)\n\nThis is the ultimate goal - using the detailed ratings to predict the binary LTR outcome \nthat drives federal reimbursement, public ratings, and patient volume."
  },
  {
   "cell_type": "code",
   "id": "509dddce-7d25-4f34-abdb-f50db95042ca",
   "metadata": {
    "language": "python",
    "name": "ExampleNewPatientData"
   },
   "outputs": [],
   "source": "#setup a sample new patient data frame\nnew_patient_ratings_df = pd.DataFrame({\n    'cleanliness': [8],\n    'communication': [9],\n    'staff_friendliness': [7],\n    'timeliness': [6],\n    'discharge_clarity': [8]\n})\n\n#show it\nst.write(\"### New Patient Survey Responses\")\nst.dataframe(new_patient_ratings_df)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae1e6add-34fa-461b-b815-fd4e354f0d76",
   "metadata": {
    "name": "PredictionProcess",
    "collapsed": false
   },
   "source": "### Prediction Process\n\nTo make a prediction, I need to:\n1. Scale the new patient data using the SAME scaler from training\n2. Apply the fitted logistic regression model\n3. Get both the binary prediction (Yes/No) and the probability"
  },
  {
   "cell_type": "code",
   "id": "8b963b12-ca7b-465f-9aac-cad983eee758",
   "metadata": {
    "language": "python",
    "name": "ScaleNewPatientData"
   },
   "outputs": [],
   "source": "#transform (scale) the new patient data ratings sample\nnew_patient_scaled = scaler.transform(new_patient_ratings_df)\n\n#show\nst.write(\"### Scaled Features\")\nst.write(\"The model requires standardized inputs (mean=0, std=1)\")\nscaled_df = pd.DataFrame(\n    new_patient_scaled,\n    columns=new_patient_ratings_df.columns\n)\nst.dataframe(scaled_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4692292-49f0-4df3-a0b0-feafec222de1",
   "metadata": {
    "language": "python",
    "name": "MakePrediction"
   },
   "outputs": [],
   "source": "#prediction model\npredicted_ltr = model.predict(new_patient_scaled)[0]\npredicted_probability = model.predict_proba(new_patient_scaled)[0, 1]\n\n#show\nst.write(\"### Prediction Results\")\nst.metric(\n    label=\"Will this patient recommend the hospital?\",\n    value=\"YES ✓\" if predicted_ltr == 1 else \"NO ✗\"\n)\nst.metric(\n    label=\"Model Confidence\",\n    value=f\"{predicted_probability:.1%}\"\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "da3492b9-3d2c-4e7d-9f6c-08cd83a739bd",
   "metadata": {
    "name": "Interpretation",
    "collapsed": false
   },
   "source": "### Interpretation\n\nMy model predicts whether this patient will say **\"Yes\"** to recommending the facility \nbased on their experience ratings.\n\n**Key Insights:**\n- **Binary Prediction**: The Yes/No answer that determines reimbursement impact\n- **Probability**: How confident the model is (higher = more certain)\n- **Threshold**: By default, probability ≥ 0.5 → \"Yes\", < 0.5 → \"No\"\n\n**Business Impact:**\n- Predictions help identify at-risk patients before they submit final surveys\n- Hospital can intervene with patients predicted to say \"No\"\n- Track which factors are dragging down individual patient scores"
  },
  {
   "cell_type": "code",
   "id": "3338d76e-10f7-4980-a1cf-ab6d5c975fbb",
   "metadata": {
    "language": "python",
    "name": "ContributingFactors"
   },
   "outputs": [],
   "source": "#I'll explore contributing factors to wrap up our analysis\n\n#start by building a contributing factors dataframe\ncontribution_df = pd.DataFrame({\n    'Factor': new_patient_ratings_df.columns,\n    'Patient_Rating': new_patient_ratings_df.iloc[0].values,\n    'Model_Coefficient': model.coef_[0],\n    'Scaled_Input': new_patient_scaled[0]\n})\n\ncontribution_df['Contribution_to_Prediction'] = (\n    contribution_df['Scaled_Input'] * contribution_df['Model_Coefficient']\n)\n\n#clean up the dataframe we just created\ncontribution_df = contribution_df.sort_values(\n    'Contribution_to_Prediction', \n    ascending=False\n)\n\n#show the contributing factors\nst.write(\"### Factor Contributions to This Prediction\")\nst.write(\"Which ratings helped/hurt this patient's likelihood to recommend?\")\nst.dataframe(\n    contribution_df[['Factor', 'Patient_Rating', 'Contribution_to_Prediction']]\n    .style.background_gradient(subset=['Contribution_to_Prediction'], cmap='RdYlGn')\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c8376fc2-e420-41ad-8436-c350b3a93d61",
   "metadata": {
    "name": "PatientPredictions",
    "collapsed": false
   },
   "source": "### Multiple Patient Predictions\n\nLet's predict for several different patient profiles to see how the model performs.\n"
  },
  {
   "cell_type": "code",
   "id": "7598a5aa-813b-46d7-b04c-c9683716bf79",
   "metadata": {
    "language": "python",
    "name": "MultiplePredictions"
   },
   "outputs": [],
   "source": "#I'll try to predict for multiple patients\n\n#start by building a multi-patient prediction dataframe with various survey results\nmultiple_patients_df = pd.DataFrame({\n    'cleanliness': [9, 5, 7, 10, 3],\n    'communication': [9, 4, 8, 9, 4],\n    'staff_friendliness': [10, 6, 7, 10, 5],\n    'timeliness': [8, 5, 6, 9, 2],\n    'discharge_clarity': [9, 5, 8, 10, 4]\n})\n\n#transform and predict on those survey results\nmultiple_patients_scaled = scaler.transform(multiple_patients_df)\nmultiple_predictions = model.predict(multiple_patients_scaled)\nmultiple_probabilities = model.predict_proba(multiple_patients_scaled)[:, 1]\n\n#build the results dataframe\nresults_df = multiple_patients_df.copy()\nresults_df['Predicted_LTR'] = ['Yes' if p == 1 else 'No' for p in multiple_predictions]\nresults_df['Probability'] = [f\"{p:.1%}\" for p in multiple_probabilities]\n\n#show the recommendation prediction based on the survey results provided\nst.write(\"### Batch Predictions for Multiple Patients\")\nst.dataframe(results_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "464197b5-4bc3-4d6e-b8e9-a6ebbf590497",
   "metadata": {
    "language": "python",
    "name": "VisualPredictions"
   },
   "outputs": [],
   "source": "#build our confidence plot\nfig, ax = plt.subplots(figsize=(10, 6))\n\ncolors = ['green' if p == 1 else 'red' for p in multiple_predictions]\nbars = ax.bar(range(len(multiple_probabilities)), multiple_probabilities, color=colors, alpha=0.6)\n\nax.axhline(y=0.5, color='black', linestyle='--', label='Decision Threshold (0.5)')\nax.set_xlabel('Patient ID')\nax.set_ylabel('Predicted Probability of LTR = Yes')\nax.set_title('Prediction Confidence for Multiple Patients')\nax.set_ylim(0, 1)\nax.legend()\n\n#plot my predictions\nfor i, (prob, pred) in enumerate(zip(multiple_probabilities, multiple_predictions)):\n    ax.text(i, prob + 0.02, f\"{prob:.2f}\", ha='center', fontsize=9)\n\n#show the plot\nst.pyplot(fig)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33ef3064-0bdf-4538-820a-2cbcb6f8bee2",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "## Key Takeaways for Hospital Leadership\n\n### Answering \"Would This Patient Recommend Us?\"\n\n**Yes, this can be predicted!** The model uses the five experience ratings to forecast LTR.\n\n### Practical Applications:\n\n1. **Early Warning System**: Identify patients likely to say \"No\" before final survey\n2. **Targeted Interventions**: Reach out to at-risk patients to address concerns\n3. **Resource Allocation**: Focus on factors with highest coefficients for maximum impact\n4. **Performance Monitoring**: Track predicted vs. actual LTR rates over time\n\n### Recommendations:\n\n- Deploy model to score patients in real-time after discharge\n- Set up alerts when predicted probability < 0.5\n- A/B test interventions on low-scoring patients\n- Monitor model performance and retrain quarterly\n\n### Final Thoughts:\n\n- Logistic regression learns the relationship between those detailed ratings and the LTR outcome.\n- Then it uses those patterns to predict whether a new patient will say \"Yes\" or \"No\" to recommending the hospital.\n- LTR it perfect for this analysis due to the binary nature of the outcome (\"Yes\" or \"No\").\n- LTR gives interpretable coefficients telling us which factors matter most.\n- LTR provides probabilities indicating how confident I am in each prediction.\n- LTR also shows odds ratios which help to quantify the impact of each factor.\n\n✅ **YES, using Logistic Regression to transform those five detailed experience ratings into \na recommendation prediction makes perfect sense!**"
  }
 ]
}