{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "taezp3v744zyslbyxhkd",
   "authorId": "1043139642183",
   "authorName": "GASULLIVAN",
   "authorEmail": "sullivangregorya@wustl.edu",
   "sessionId": "006111b8-efe5-4227-bf2c-2c25495d519f",
   "lastEditTime": 1758235396079
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "Section1",
    "collapsed": false
   },
   "source": "Section 1: Group Comparisons with Continuous Data\nThis exercise will be done in Python via a Snowflake Notebook.\n\n1.\tRead the males_ht_wt_cntry.csv file into a data frame\n2.\tExamine the data\na.\tDisplay some rows to make sure it imported correctly\nb.\tGenerate histograms of the heights by country using Altair or Seaborn charts\nc.\tGenerate histograms of the weights by country using Altair or Seaborn charts\n\n3.\tConduct an ANOVA test to determine if the weights differ by nationality and interpret your results. Use this link as a reference. Make sure you use Levene’s test to check if the variance is close to equal.\n\n4.\tANOVA won’t tell you which sets of weights differ. You will need to compare each group against each other to determine that. Use this link as a reference.\na.\tConduct a test to determine if the weights of the Italian males were significantly different than the Dutch males (from the Netherlands) and interpret your results\nb.\tConduct a test to determine if the weights of the American males were significantly different than the Dutch males (from the Netherlands) and interpret your results\n\n5.\tConducting multiple tests like this increases the odds of getting false significant results. If you had conducted tests for 3 comparisons (Italian vs Dutch, Italian vs American, American vs Dutch), what is the probability one of these t-tests is not actually significant (i.e. false positive)?\n\n6.\tWhen comparing these groups, it’s better to control the Family-Wise Error Rate (FWER). Use a multiple comparison procedure with a Tukey adjustment. See this link for how to do this in using the pairwise_tukeyhsd() function (statsmodels.stats.multicomp.pairwise_tukeyhsd).\n\n"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "ReadCSVintoDataFrame"
   },
   "source": "\"\"\"\n1.Read the males_ht_wt_cntry.csv file into a data frame\n\"\"\"\n\nimport pandas as pd\n\n# read the file into a DataFrame\ndf = pd.read_csv(\"males_ht_wt_cntry.csv\")\n\n# display first few rows\ndf.head()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "ExamineTheData"
   },
   "source": "\"\"\"\n2.\tExamine the data\n    a.\tDisplay some rows to make sure it imported correctly\n    b.\tGenerate histograms of the heights by country using Altair or Seaborn charts\n    c.\tGenerate histograms of the weights by country using Altair or Seaborn charts\n\"\"\"\n\n#print data types and missing values\ndf.info()\n\n#summary statistics\ndf.describe()\n\n#how many rows and columns are there\ndf.shape\n\n#a.\tDisplay some rows to make sure it imported correctly\n#b.\tGenerate histograms of the heights by country using Altair or Seaborn charts\n#c.\tGenerate histograms of the weights by country using Altair or Seaborn charts\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#histogram of height by country\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x=\"Height\", hue=\"Country\", kde=True, element=\"step\", stat=\"density\", bins=20)\n\nplt.title(\"Histogram of Heights by Country\")\nplt.xlabel(\"Height\")\nplt.ylabel(\"Density\")\nplt.tight_layout()\nplt.show()\n\n#histogram of weight by country\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x=\"Weight\", hue=\"Country\", kde=True, element=\"step\", stat=\"density\", bins=20)\n\nplt.title(\"Histogram of Weights by Country\")\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Density\")\n#plt.legend(title=\"Country\")\nplt.tight_layout()\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fa169217-e65f-4158-9b43-dc7c0b41a2db",
   "metadata": {
    "language": "python",
    "name": "ANOVA"
   },
   "outputs": [],
   "source": "\"\"\"\n3.\tConduct an ANOVA test to determine if the weights differ by nationality and interpret your results. \nUse this link as a reference. Make sure you use Levene’s test to check if the variance is close to equal.\n\"\"\"\nimport pandas as pd\nfrom scipy.stats import f_oneway, levene\n\n# Get list of countries\ncountries = df['Country'].unique()\n\n# Create a list of weight arrays, one per country\nweight_groups = [df[df['Country'] == country]['Weight'].dropna() for country in countries]\n\n# Levene's test checks homogeneity of variances (null: equal variance)\nlevene_stat, levene_p = levene(*weight_groups)\n\nprint(f\"Levene’s Test Statistic: {levene_stat:.4f}\")\nprint(f\"Levene’s Test p-value: {levene_p:.4f}\")\n\nif levene_p < 0.05:\n    print(\"Variances are significantly different (p < 0.05), use Welch's ANOVA.\\n\\n\")\nelse:\n    print(\"Variances are not significantly different (p ≥ 0.05), standard ANOVA is appropriate.\\n\\n\")\n\n\nanova_stat, anova_p = f_oneway(*weight_groups)\n\nprint(f\"ANOVA F-Statistic: {anova_stat:.4f}\")\nprint(f\"ANOVA p-value: {anova_p:.4f}\")\n\nif anova_p < 0.05:\n    print(\"Reject the null hypothesis: There is a statistically significant difference in average weight by country.\")\nelse:\n    print(\"Fail to reject the null hypothesis: No significant difference in weight by country.\")\n\nlevene_stat, levene_p = levene(*weight_groups)\n\nprint(f\"Levene’s Test Statistic: {levene_stat:.4f}\")\nprint(f\"Levene’s Test p-value: {levene_p:.4f}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "66674afe-78eb-4278-8a01-7dd751e96415",
   "metadata": {
    "name": "LeveneComments",
    "collapsed": false
   },
   "source": "Levene’s Test for Equal Variance\n\tStatistic: 2.6579\n\tp-value: 0.0722\n    \nInterpretation: Since p > 0.05, we fail to reject the null hypothesis — this means the variances in weight are not significantly different between countries."
  },
  {
   "cell_type": "markdown",
   "id": "1f751615-07dc-458b-b6a0-deb2e9104e76",
   "metadata": {
    "name": "ANOVAComments",
    "collapsed": false
   },
   "source": " One-Way ANOVA (Weight by Country)\n\tF-statistic: 73.0317\n\tp-value: 0.0000\nInterpretation: The p-value is extremely small, well below 0.05.\n\nWe reject the null hypothesis and conclude that there is a statistically significant difference in mean weight across the countries."
  },
  {
   "cell_type": "markdown",
   "id": "28ba029f-0322-4a29-9b94-4534e5037217",
   "metadata": {
    "name": "LeveneANOVAInterpretation",
    "collapsed": false
   },
   "source": "So, Levene says the \"spread\" of data in each group is similar (as tested by the variance).\n\nWhile ANOVA says the \"center\" of at least one group is different (as tested by the mean)."
  },
  {
   "cell_type": "markdown",
   "id": "a7b4488c-f265-473f-a4c2-793b7f5ba72d",
   "metadata": {
    "name": "ANOVAClarification",
    "collapsed": false
   },
   "source": "4.\tANOVA won’t tell you which sets of weights differ. You will need to compare each group against each other to determine that. Use this link as a reference.\na.\tConduct a test to determine if the weights of the Italian males were significantly different than the Dutch males (from the Netherlands) and interpret your results\nb.\tConduct a test to determine if the weights of the American males were significantly different than the Dutch males (from the Netherlands) and interpret your results\n\n"
  },
  {
   "cell_type": "code",
   "id": "9e2bcc06-86a3-426a-8bab-bc8e77bed910",
   "metadata": {
    "language": "python",
    "name": "ANOVAClarificatonCode"
   },
   "outputs": [],
   "source": "import pandas as pd\nfrom scipy.stats import ttest_ind\n\n# Load the dataset (update path as needed if you're not in a local Jupyter or Snowflake Notebook)\ndf = pd.read_csv(\"males_ht_wt_cntry.csv\")  # or the path to your file\n\n# Extract weight data by country\nitaly_weights = df[df['Country'] == 'Italy']['Weight']\nnetherlands_weights = df[df['Country'] == 'Netherlands']['Weight']\nusa_weights = df[df['Country'] == 'USA']['Weight']\n\n# --- a. Italy vs Netherlands ---\nt_stat_italy_nl, p_val_italy_nl = ttest_ind(italy_weights, netherlands_weights, equal_var=True)\nprint(\"Italy vs Netherlands:\")\nprint(f\"  t-statistic: {t_stat_italy_nl:.4f}\")\nprint(f\"  p-value: {p_val_italy_nl:.4f}\")\nif p_val_italy_nl < 0.05:\n    print(\"  ➜ Statistically significant difference in mean weight.\\n\")\nelse:\n    print(\"  ➜ No statistically significant difference.\\n\")\n\n# --- b. USA vs Netherlands ---\nt_stat_usa_nl, p_val_usa_nl = ttest_ind(usa_weights, netherlands_weights, equal_var=True)\nprint(\"USA vs Netherlands:\")\nprint(f\"  t-statistic: {t_stat_usa_nl:.4f}\")\nprint(f\"  p-value: {p_val_usa_nl:.4f}\")\nif p_val_usa_nl < 0.05:\n    print(\"  ➜ Statistically significant difference in mean weight.\\n\")\nelse:\n    print(\"  ➜ No statistically significant difference.\\n\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de0ebdbf-f24e-48c4-95a0-1e0b220ed492",
   "metadata": {
    "name": "ANOVAClarificationInterpretation",
    "collapsed": false
   },
   "source": "a. Italy vs Netherlands\n\t•\tt-statistic: -11.1358\n\t•\tp-value: 0.0000\n\nInterpretation:\nThere IS a statistically significant difference in the average weight between Italian and Dutch males.\nSince the p-value is well below the 0.05 threshold, we can confidently reject the null hypothesis that their mean weights are equal.\nThe negative t-statistic suggests that, on average, Italian males weigh less than Dutch males.\n\n⸻\n\nb. USA vs Netherlands\n\t•\tt-statistic: 0.3921\n\t•\tp-value: 0.6955\n\nInterpretation:\nThere is NO statistically significant difference in the average weight between American and Dutch males.\nBecause the p-value is well above 0.05, we fail to reject the null hypothesis — this means that any observed difference in weight could be due to random chance, not a true difference in the population."
  },
  {
   "cell_type": "markdown",
   "id": "45894b1f-da45-4c04-9910-e9ade8642cd3",
   "metadata": {
    "name": "MultipleTests",
    "collapsed": false
   },
   "source": "5.\tConducting multiple tests like this increases the odds of getting false significant results. If you had conducted tests for 3 comparisons (Italian vs Dutch, Italian vs American, American vs Dutch), what is the probability one of these t-tests is not actually significant (i.e. false positive)?\n\nWhen I t-test a hypothesis I'm typically looking for a significance level (α) of 0.05, meaning there’s a 5% chance of a false positive — i.e., rejecting the null hypothesis when it’s actually true. However, when I conduct multiple tests, the probability that at least one test will yield a false positive increases.\n\nIf I run 3 independent tests, what is the probability that at least one of them results in a false positive (assuming all null hypotheses are actually true)?\n\n⸻\n\nI compute this using the complement rule:\n\nP(\\text{at least one false positive}) = 1 - (1 - \\alpha)^n\n\nWhere:\n\t•\talpha = 0.05 (significance level)\n\t•\tn = 3 (number of tests)\n\nP = 1 - (1 - alpha)^n = 1 - (1-alpha)^n = 1 - 0.857375 = 0.142625\n\n"
  },
  {
   "cell_type": "code",
   "id": "3f291334-6859-404f-933b-65e3e7637e55",
   "metadata": {
    "language": "python",
    "name": "ComplementRule"
   },
   "outputs": [],
   "source": "# Parameters\nalpha = 0.05       # significance level\nnum_tests = 3      # number of independent tests\n\n# Compute the probability of at least one false positive\nprob_false_positive = 1 - (1 - alpha) ** num_tests\n\n# Display result\nprint(f\"Probability of at least one false positive (Type I error) out of {num_tests} tests: {prob_false_positive:.4f}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18d9e7eb-202e-4352-9213-36a5ba9ef2ad",
   "metadata": {
    "name": "ComparingTheseGroups",
    "collapsed": false
   },
   "source": "6.\tWhen comparing these groups, it’s better to control the Family-Wise Error Rate (FWER). Use a multiple comparison procedure with a Tukey adjustment. See this link for how to do this in using the pairwise_tukeyhsd() function (statsmodels.stats.multicomp.pairwise_tukeyhsd)."
  },
  {
   "cell_type": "code",
   "id": "22e8ec01-4130-4ef6-86c6-dcde46f5856e",
   "metadata": {
    "language": "python",
    "name": "TukeyHSDTest"
   },
   "outputs": [],
   "source": "import pandas as pd\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# Load the dataset\ndf = pd.read_csv(\"males_ht_wt_cntry.csv\")  # Adjust path if needed\n\n# Run Tukey's HSD test\ntukey = pairwise_tukeyhsd(endog=df['Weight'], groups=df['Country'], alpha=0.05)\n\n# Print the summary\nprint(tukey.summary())",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "775cfaa7-f70f-4ab9-886d-c1b0dbe1381d",
   "metadata": {
    "name": "Section2",
    "collapsed": false
   },
   "source": "Section 2: Group Comparisons with Categorical Data\n\tCreate a new BMI column. Use the Imperial formula BMI=  (Weight*703)/〖Height〗^2 . \n\n\tCreate another new column ‘Overweight’ that is a 1 if BMI >= 25 and 0 otherwise. There are several ways to do this in Python. \n\n\tCreate a contingency table of overweight by nationality and examine it. Describe any differences you see between nationalities.\n\n\tConduct a Chi-Sq test using scipy.stats to see if the differences are significant. Explain your findings.\n\n"
  },
  {
   "cell_type": "code",
   "id": "7e67a5b2-f39b-4db0-a940-3914cee29942",
   "metadata": {
    "language": "python",
    "name": "Section2Code"
   },
   "outputs": [],
   "source": "import pandas as pd\nfrom scipy.stats import chi2_contingency\n\n# Load the dataset\ndf = pd.read_csv(\"males_ht_wt_cntry.csv\")  # Adjust path if needed\n\n# Step 1: Calculate BMI using the imperial formula\ndf['BMI'] = (df['Weight'] * 703) / (df['Height'] ** 2)\n\n# Step 2: Flag overweight (BMI >= 25)\ndf['Overweight'] = (df['BMI'] >= 25).astype(int)\n\n# Step 3: Create contingency table (Country vs Overweight)\ncontingency = pd.crosstab(df['Country'], df['Overweight'])\n\n# Step 4: Perform Chi-Square test\nchi2, p, dof, expected = chi2_contingency(contingency)\n\n# Step 5: Print results\nprint(\"Contingency Table (0 = not overweight, 1 = overweight):\")\nprint(contingency)\nprint(\"\\nExpected Frequencies:\")\nprint(pd.DataFrame(expected, index=contingency.index, columns=contingency.columns))\nprint(\"\\nChi-Square Test Results:\")\nprint(f\"Chi-Square Statistic: {chi2:.4f}\")\nprint(f\"Degrees of Freedom: {dof}\")\nprint(f\"p-value: {p:.4f}\")\n\n# Optional: Interpretation based on p-value\nif p < 0.05:\n    print(\"\\nThere is a statistically significant relationship between nationality and overweight status.\")\nelse:\n    print(\"\\nNo statistically significant relationship found.\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be187fca-5b44-4e46-9675-a33e5eda62c5",
   "metadata": {
    "name": "Section2Interpretation",
    "collapsed": false
   },
   "source": "1.\tUSA:\n\t•\tHas the highest number and proportion of overweight males, which I know from our frequent travels to Europe!\n\t•\tOver 57% (52 out of 90) are classified as overweight.\n\t•\tIndicates a strong trend toward higher BMI values compared to other countries.\n\t2.\tItaly:\n\t•\tHas the lowest number and proportion of overweight males.\n\t•\tOnly about 23% (16 out of 70) are overweight.\n\t•\tSuggests that Italian males in this dataset tend to have lower BMI values.\n\t3.\tNetherlands:\n\t•\tFalls in the middle.\n\t•\t40% (32 out of 80) are overweight, but this does not align with my personal observation\n\t•\tThis shows a moderate level of overweight prevalence.\n\n⸻\n\nSummary:\n\t•\tThe proportion of overweight individuals increases from Italy → Netherlands → USA.\n\t•\tThese patterns reflect clear differences in average body mass across the countries in this sample.\n\t•\tThe Chi-Square test confirms these differences are statistically significant — they are unlikely due to random variation alone."
  },
  {
   "cell_type": "markdown",
   "id": "20a53c63-755e-448e-90c2-c31c34829f5f",
   "metadata": {
    "name": "LinearRegression",
    "collapsed": false
   },
   "source": "1.\tBuild a linear regression of to see whether height predicts weight. There are two main modules for conducting linear regression in Python. Use statsmodels. Explain the results. \n\n2.\tFit the same regression model using linear algebra. Compare your resultant ’s to the ones you obtained earlier. \n\n\n"
  },
  {
   "cell_type": "code",
   "id": "88de22f7-595c-4d74-9127-a9a803fcf908",
   "metadata": {
    "language": "python",
    "name": "ContingencyTableCode"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\n\n# Load the dataset\ndf = pd.read_csv(\"males_ht_wt_cntry.csv\")  # Adjust path if needed\n\n# --- Part 1: Linear Regression using statsmodels ---\n# Define independent and dependent variables\nX = df['Height']\ny = df['Weight']\n\n# Add a constant (intercept) to the model\nX_with_const = sm.add_constant(X)\n\n# Fit the model\nmodel = sm.OLS(y, X_with_const).fit()\n\n# Print results\nprint(\"=== Statsmodels Regression Results ===\")\nprint(model.summary())\nprint()\n\n# --- Part 2: Linear Regression using Linear Algebra ---\n# Prepare matrices\nX_matrix = np.vstack([np.ones(len(X)), X]).T  # Add intercept column manually\ny_vector = y.values.reshape(-1, 1)\n\n# Calculate beta coefficients using normal equation\nbeta_hat = np.linalg.inv(X_matrix.T @ X_matrix) @ (X_matrix.T @ y_vector)\n\n# Display results\nprint(\"=== Linear Algebra Regression Coefficients ===\")\nprint(f\"Intercept (β₀): {beta_hat[0][0]:.4f}\")\nprint(f\"Slope     (β₁): {beta_hat[1][0]:.4f}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "61309ac9-3da4-4600-896b-8b3cdf3b5938",
   "metadata": {
    "name": "LinearRegressionInterpretation",
    "collapsed": false
   },
   "source": "Regression Results (from statsmodels):\n\t•\tIntercept (β₀): -28.2547\n\t•\tSlope (β₁): 2.8537\n\t•\tR-squared: 0.3635\n\t•\tF-statistic p-value: < 0.0001 (very significant)\n\nInterpretation:\n\t•\tFor every additional inch in height, a male’s weight increases by approximately 2.85 lbs, on average.\n\t•\tThe intercept is negative, which means at a height of 0 inches, the predicted weight is negative (which is not meaningful physically, but it’s just the y-intercept of the linear fit).\n\t•\tThe R² value of 0.364 tells us that about 36% of the variation in weight is explained by height — this is moderate explanatory power.\n\t•\tThe F-statistic and p-value show that the model is statistically significant overall.\n\n⸻\n\n2. Linear Regression Using Linear Algebra\n\nWe used the normal equation:\n\n\\hat{\\beta} = (X^TX)^{-1}X^Ty\n\t•\tIntercept (β₀): -28.2547\n\t•\tSlope (β₁): 2.8537\n\nThese match exactly with the coefficients from statsmodels, confirming the accuracy of the linear algebra implementation.\n\n⸻\n\nSummary:\n\t•\tBoth methods yield identical coefficients.\n\t•\tHeight is a statistically significant predictor of weight.\n\t•\tHowever, since R² is only ~0.36, other factors (e.g., body composition, nationality, age) likely also influence weight."
  },
  {
   "cell_type": "code",
   "id": "89388fc3-a25a-4866-bb2e-43ddc34d17ff",
   "metadata": {
    "language": "python",
    "name": "NewTable"
   },
   "outputs": [],
   "source": "import pandas as pd\n\n# Load the data\ndf = pd.read_csv(\"males_ht_wt_cntry.csv\")\n\n# Create BMI column\ndf['BMI'] = (df['Weight'] * 703) / (df['Height'] ** 2)\n\n# Create Overweight column (1 if BMI >= 25, else 0)\ndf['Overweight'] = (df['BMI'] >= 25).astype(int)\n\n# Display the updated dataframe\n# print(df.head())  # Use .head() to show the first 5 rows\nprint(df)",
   "execution_count": null
  }
 ]
}